<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Agent 技术调研 | Genluo</title><meta name=keywords content="AI"><meta name=description content="Agent 相关技术调研，按照自己的层级思路，具体的介绍是AI生成的"><meta name=author content><link rel=canonical href=https://genluo.github.io/my-blog/posts/agent/><link crossorigin=anonymous href=/my-blog/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://genluo.github.io/my-blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://genluo.github.io/my-blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://genluo.github.io/my-blog/favicon-32x32.png><link rel=apple-touch-icon href=https://genluo.github.io/my-blog/apple-touch-icon.png><link rel=mask-icon href=https://genluo.github.io/my-blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://genluo.github.io/my-blog/posts/agent/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.jsdelivr.net/npm/mermaid@latest/dist/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){mermaid.init({theme:"dark"},".language-mermaid")})</script><style>.language-mermaid{background-color:#333;border-radius:6px;padding:10px}</style><meta property="og:url" content="https://genluo.github.io/my-blog/posts/agent/"><meta property="og:site_name" content="Genluo"><meta property="og:title" content="Agent 技术调研"><meta property="og:description" content="Agent 相关技术调研，按照自己的层级思路，具体的介绍是AI生成的"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-28T17:45:42+08:00"><meta property="article:modified_time" content="2025-10-28T17:45:42+08:00"><meta property="article:tag" content="AI"><meta name=twitter:card content="summary"><meta name=twitter:title content="Agent 技术调研"><meta name=twitter:description content="Agent 相关技术调研，按照自己的层级思路，具体的介绍是AI生成的"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://genluo.github.io/my-blog/posts/"},{"@type":"ListItem","position":2,"name":"Agent 技术调研","item":"https://genluo.github.io/my-blog/posts/agent/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Agent 技术调研","name":"Agent 技术调研","description":"Agent 相关技术调研，按照自己的层级思路，具体的介绍是AI生成的","keywords":["AI"],"articleBody":"Agent 内容 整个 Agent 相关技术拆为两个大的部分进行介绍，一个是对应的工作流，一个是对应的 Agent 开发相关技术\n工作流介绍 顺序执行型：ReAct、Plan \u0026 Execute、流水式、提示链 协作优化型：自协商、评估优化、多智能体协作、分层规划 动态编排型：动态编排、自演化、混合模式、路由、并行化、协调者-工作者 顺序执行型 1. ReAct 通过推理（Reasoning）和行动（Acting）交替循环的方式，让Agent在思考和执行工具之间迭代，直到完成任务。\nstateDiagram-v2 [*] --\u003e 接收任务 接收任务 --\u003e 推理思考 推理思考 --\u003e 判断是否需要行动 判断是否需要行动 --\u003e 执行工具: 需要行动 判断是否需要行动 --\u003e 生成答案: 无需行动 执行工具 --\u003e 观察结果 观察结果 --\u003e 推理思考 生成答案 --\u003e [*] 2. Plan \u0026 Execute 先制定完整的执行计划，然后按照计划逐步执行各个步骤，适合复杂任务的分解与执行。\nstateDiagram-v2 [*] --\u003e 接收任务 接收任务 --\u003e 规划阶段 规划阶段 --\u003e 生成执行计划 生成执行计划 --\u003e 执行步骤1 执行步骤1 --\u003e 执行步骤2 执行步骤2 --\u003e 执行步骤N 执行步骤N --\u003e 检查完成状态 检查完成状态 --\u003e 返回结果: 已完成 检查完成状态 --\u003e 重新规划: 需调整 重新规划 --\u003e 生成执行计划 返回结果 --\u003e [*] 3. 流水式 将任务按固定顺序分配到多个专门的Agent，每个Agent处理特定环节后传递给下一个，形成处理流水线。\nstateDiagram-v2 [*] --\u003e Agent1 Agent1 --\u003e Agent2: 输出1 Agent2 --\u003e Agent3: 输出2 Agent3 --\u003e Agent4: 输出3 Agent4 --\u003e 最终输出 最终输出 --\u003e [*] 4. 提示链 通过将复杂任务拆解为一系列简单的提示步骤，每步的输出作为下一步的输入，形成提示链式传递。\nstateDiagram-v2 [*] --\u003e Prompt1 Prompt1 --\u003e 生成中间结果1 生成中间结果1 --\u003e Prompt2 Prompt2 --\u003e 生成中间结果2 生成中间结果2 --\u003e Prompt3 Prompt3 --\u003e 生成中间结果3 生成中间结果3 --\u003e PromptN PromptN --\u003e 最终结果 最终结果 --\u003e [*] 协作优化型 1. 自协商 Agent通过自我对话或多角色辩论的方式，从不同视角审视问题，通过协商达成更优的解决方案。\nstateDiagram-v2 [*] --\u003e 接收任务 接收任务 --\u003e 生成初始方案 生成初始方案 --\u003e 角色A提出观点 角色A提出观点 --\u003e 角色B反驳质疑 角色B反驳质疑 --\u003e 角色A回应改进 角色A回应改进 --\u003e 评估是否达成共识 评估是否达成共识 --\u003e 角色B反驳质疑: 未达成 评估是否达成共识 --\u003e 输出协商结果: 已达成 输出协商结果 --\u003e [*] 2. 评估优化 通过独立的评估者Agent对执行结果进行评分和反馈，执行者根据反馈持续优化，直到达到质量标准。\nstateDiagram-v2 [*] --\u003e 执行者生成初始输出 执行者生成初始输出 --\u003e 评估者评分 评估者评分 --\u003e 评估者提供改进建议 评估者提供改进建议 --\u003e 判断质量 判断质量 --\u003e 执行者优化改进: 未达标 判断质量 --\u003e 输出最终结果: 已达标 执行者优化改进 --\u003e 评估者评分 输出最终结果 --\u003e [*] 3. 多智能体协作 多个具有不同专长的 Agent 协同工作，通过信息共享和任务分配，发挥各自优势完成复杂任务。\nstateDiagram-v2 [*] --\u003e 任务分配器 任务分配器 --\u003e Agent1专家 任务分配器 --\u003e Agent2专家 任务分配器 --\u003e Agent3专家 Agent1专家 --\u003e 共享信息池 Agent2专家 --\u003e 共享信息池 Agent3专家 --\u003e 共享信息池 共享信息池 --\u003e 协调者 协调者 --\u003e 判断是否完成 判断是否完成 --\u003e 分配后续任务: 未完成 判断是否完成 --\u003e 结果汇总: 已完成 分配后续任务 --\u003e Agent1专家 分配后续任务 --\u003e Agent2专家 分配后续任务 --\u003e Agent3专家 结果汇总 --\u003e [*] 4. 分层规划 采用层次化的规划策略，高层Agent负责宏观规划和目标分解，低层Agent负责具体执行，实现复杂任务的结构化管理。\nstateDiagram-v2 [*] --\u003e 高层规划Agent 高层规划Agent --\u003e 制定战略目标 制定战略目标 --\u003e 分解为子目标 分解为子目标 --\u003e 中层规划Agent 中层规划Agent --\u003e 制定执行计划 制定执行计划 --\u003e 分配具体任务 分配具体任务 --\u003e 低层执行Agent 低层执行Agent --\u003e 执行具体操作 执行具体操作 --\u003e 向上反馈结果 向上反馈结果 --\u003e 中层规划Agent 中层规划Agent --\u003e 评估进度 评估进度 --\u003e 高层规划Agent: 汇报总体进展 高层规划Agent --\u003e 判断目标完成 判断目标完成 --\u003e 调整战略: 需调整 判断目标完成 --\u003e 输出最终结果: 已完成 调整战略 --\u003e 分解为子目标 输出最终结果 --\u003e [*] 动态编排型 1. 动态编排 根据任务执行过程中的实时状态和反馈，动态调整工作流程和 Agent 组合，实现灵活的任务编排。\nstateDiagram-v2 [*] --\u003e 接收任务 接收任务 --\u003e 分析任务特征 分析任务特征 --\u003e 动态生成工作流 动态生成工作流 --\u003e 执行当前步骤 执行当前步骤 --\u003e 评估执行状态 评估执行状态 --\u003e 判断是否需要调整 判断是否需要调整 --\u003e 重新编排工作流: 需要调整 判断是否需要调整 --\u003e 继续执行: 无需调整 重新编排工作流 --\u003e 执行当前步骤 继续执行 --\u003e 判断任务完成 判断任务完成 --\u003e 执行当前步骤: 未完成 判断任务完成 --\u003e 输出结果: 已完成 输出结果 --\u003e [*] 2. 自演化 Agent 通过学习历史经验和反馈，不断优化自身的提示词、工具选择和决策策略，实现自我进化。\nstateDiagram-v2 [*] --\u003e 初始化Agent 初始化Agent --\u003e 执行任务 执行任务 --\u003e 收集执行数据 收集执行数据 --\u003e 分析成功失败案例 分析成功失败案例 --\u003e 提取经验模式 提取经验模式 --\u003e 更新策略库 更新策略库 --\u003e 优化提示词 优化提示词 --\u003e 调整工具选择 调整工具选择 --\u003e 升级Agent版本 升级Agent版本 --\u003e 验证新版本 验证新版本 --\u003e 执行任务: 持续进化 验证新版本 --\u003e 回滚版本: 效果变差 回滚版本 --\u003e 执行任务 3. 混合模式 结合多种工作流模式的优势，针对不同子任务采用最适合的执行模式，形成混合工作流架构。\nstateDiagram-v2 [*] --\u003e 任务分析 任务分析 --\u003e 子任务1 任务分析 --\u003e 子任务2 任务分析 --\u003e 子任务3 子任务1 --\u003e ReAct模式 子任务2 --\u003e 流水式模式 子任务3 --\u003e 多智能体协作模式 ReAct模式 --\u003e 结果汇总 流水式模式 --\u003e 结果汇总 多智能体协作模式 --\u003e 结果汇总 结果汇总 --\u003e 整合输出 整合输出 --\u003e [*] 4. 路由 根据任务类型、复杂度或领域特征，智能路由到最适合的 Agent 或处理流程，实现任务的精准分发。\nstateDiagram-v2 [*] --\u003e 接收任务 接收任务 --\u003e 路由分析器 路由分析器 --\u003e 判断任务类型 判断任务类型 --\u003e 简单查询Agent: 简单查询 判断任务类型 --\u003e 复杂推理Agent: 复杂推理 判断任务类型 --\u003e 代码生成Agent: 代码任务 判断任务类型 --\u003e 数据分析Agent: 数据分析 简单查询Agent --\u003e 返回结果 复杂推理Agent --\u003e 返回结果 代码生成Agent --\u003e 返回结果 数据分析Agent --\u003e 返回结果 返回结果 --\u003e [*] 5. 并行化 将独立的子任务或步骤并行分配给多个 Agent 同时执行，显著提升整体执行效率。\nstateDiagram-v2 [*] --\u003e 任务分解 任务分解 --\u003e 并行执行 state 并行执行 { [*] --\u003e Agent1 [*] --\u003e Agent2 [*] --\u003e Agent3 [*] --\u003e Agent4 Agent1 --\u003e [*] Agent2 --\u003e [*] Agent3 --\u003e [*] Agent4 --\u003e [*] } 并行执行 --\u003e 等待所有任务完成 等待所有任务完成 --\u003e 结果聚合 结果聚合 --\u003e 最终输出 最终输出 --\u003e [*] 6. 协调者-工作者 协调者 Agent 负责任务分配、进度监控和结果整合，工作者 Agent 专注于执行具体任务，实现职责分离。\nstateDiagram-v2 [*] --\u003e 协调者接收任务 协调者接收任务 --\u003e 协调者分析任务 协调者分析任务 --\u003e 协调者分配任务 协调者分配任务 --\u003e 工作者1执行 协调者分配任务 --\u003e 工作者2执行 协调者分配任务 --\u003e 工作者3执行 工作者1执行 --\u003e 工作者1报告进度 工作者2执行 --\u003e 工作者2报告进度 工作者3执行 --\u003e 工作者3报告进度 工作者1报告进度 --\u003e 协调者监控 工作者2报告进度 --\u003e 协调者监控 工作者3报告进度 --\u003e 协调者监控 协调者监控 --\u003e 判断完成状态 判断完成状态 --\u003e 协调者调整策略: 需要调整 判断完成状态 --\u003e 协调者整合结果: 全部完成 协调者调整策略 --\u003e 协调者分配任务 协调者整合结果 --\u003e 输出最终结果 输出最终结果 --\u003e [*] Agent 相关技术 上下文 问题 1. 上下文中毒 指错误信息、幻觉内容或过时数据被写入 Agent 的上下文后，被模型反复引用、强化，最终导致整个推理链条崩坏的现象。一旦错误信息进入上下文，模型会将其视为可信事实，在后续推理中不断基于这些错误前提进行演绎，形成错误累积和放大效应。\n解决思路：建立信息源可信度评估机制，对外部输入进行验证；引入事实核查层，对关键信息进行交叉验证；使用时间戳标记上下文信息的时效性，定期更新过时数据；实施上下文质量监控，检测推理链中的逻辑矛盾；采用多路径验证策略，通过不同推理路径交叉印证结果的正确性。\n2. 上下文干扰 指上下文中存在过多无关或冗余信息，干扰模型对关键信息的识别和处理。在长对话或复杂任务中，早期的无关细节可能分散模型注意力，降低对当前任务重点的把握能力。\n解决思路：采用上下文压缩技术提取关键信息摘要；实施滑动窗口机制只保留最近的相关对话；使用相关性评分算法筛选高价值信息；引入注意力引导提示词明确指向当前任务重点；定期进行上下文清理，移除过时或无关内容。\n3. 上下文混淆 指多个任务或对话线程的信息在上下文中交织，导致模型无法正确区分和关联相关信息。当处理多轮嵌套对话或并行任务时，模型可能混淆不同场景的参数、状态或目标。在 MCP（Model Context Protocol）场景中，当可用工具数量过多时，模型难以准确匹配工具功能与任务需求，容易选错工具或混淆相似工具的使用场景。\n解决思路：为不同任务或对话线程分配独立的上下文空间；使用明确的标识符或分隔标记区分不同场景；采用命名空间机制隔离不同任务的状态和变量；建立上下文索引系统快速定位相关信息；在提示词中显式声明当前操作的任务范围；对于 MCP 工具管理，采用分层分类组织工具，根据任务类型动态加载相关工具子集，使用语义化的工具描述和示例增强工具识别度。\n4. 上下文飘移 指随着交互轮次增加，上下文逐渐偏离原始任务目标或主题的现象。模型可能在长对话中逐步丢失初始意图，转向相关但非核心的话题，导致最终输出与用户预期不符。\n解决思路：在上下文中持久化保留原始任务目标作为锚点；定期回顾和重申初始意图；设置偏离度检测机制，当话题偏离超过阈值时触发提醒；使用目标导向的提示词模板引导对话回归主线；建立任务完成度评估体系，确保每个交互步骤与最终目标的关联性。\n技术 1. 上下文压缩 上下文压缩是应对长文本处理和上下文窗口限制的关键技术，主要包括三种方式：\n过滤式压缩（删除）：通过相关性评分、关键词匹配或语义相似度计算，筛选出与当前任务最相关的信息片段，过滤掉冗余或低价值内容，保留核心上下文，适用于需要快速降低上下文长度的场景，优势在于实现简单、效率高，但可能丢失潜在有用的边缘信息。\n提炼式压缩（浓缩）：利用摘要模型或大语言模型对原始上下文进行语义提炼，将长文本浓缩为简洁的摘要或关键点列表，保留核心语义和逻辑关系，适用于需要保持信息完整性和连贯性的场景，能够在大幅压缩的同时保持语义质量，但依赖模型的理解和生成能力，可能引入摘要偏差。\n结构化压缩：将非结构化的上下文信息转换为结构化表示，如知识图谱、表格、JSON对象或向量嵌入，通过结构化组织实现信息的高效存储和检索，适用于需要频繁查询和复用上下文的场景，优势在于支持精确检索和关系推理，但需要额外的结构化处理步骤，对信息的结构化质量要求较高。\n2. 上下文卸载 上下文卸载是将暂时不需要的上下文信息从活跃工作区转移到外部存储的技术，以释放有限的上下文窗口空间，主要包括以下几种方式：\n基于时间的卸载（LRU策略）：采用最近最少使用（Least Recently Used）算法，根据上下文信息的访问时间戳，优先卸载最久未被访问的内容，这种方式假设最近使用的信息更可能在近期再次被需要，实现简单且适用于大多数场景，但可能误卸载重要但暂时未访问的关键信息，适合处理时序性强的对话和任务。\n基于优先级的卸载：为上下文中的不同信息片段分配优先级权重，如任务目标、用户明确指令、关键决策节点等赋予高优先级，而中间推理过程、临时计算结果等赋予低优先级，当上下文空间不足时优先卸载低优先级内容，这种方式能够保护核心信息不被误删，但需要建立合理的优先级评估机制，适用于复杂任务和长期对话场景。\n基于语义相关性的卸载：通过计算上下文片段与当前任务的语义相似度或相关性评分，卸载与当前任务关联度低的历史信息，利用向量嵌入和语义检索技术动态评估信息价值，这种方式能够智能识别真正无关的内容，但计算开销较大且依赖语义理解质量，适合需要精确保留相关上下文的知识密集型任务。\n分层卸载策略：将上下文信息按照抽象层次分为不同级别，如原始对话记录、中间推理步骤、提炼后的结论和元信息等，优先卸载低层次的原始数据，保留高层次的精炼信息和摘要，这种方式在节省空间的同时保持信息的可追溯性，支持必要时从外部存储重新加载详细内容，适用于需要平衡详细度和效率的长期运行Agent。\n触发式卸载：设置上下文使用率的阈值监控机制，当上下文占用率达到预设警戒线（如80%）时自动触发卸载流程，或在任务阶段切换、对话主题转移等关键节点主动进行上下文清理，这种方式结合了被动响应和主动管理，能够在保证性能的同时避免上下文溢出，适合动态变化的交互场景和多任务并行处理。\n3. 上下文存储 上下文存储是将卸载的上下文信息持久化保存并支持高效检索的技术，确保历史信息在需要时能够快速恢复到工作区，主要包括以下几种方式：\n向量数据库存储：将上下文信息通过嵌入模型转换为高维向量表示，存储在专门的向量数据库（如Pinecone、Milvus、Weaviate）中，支持基于语义相似度的快速检索，这种方式能够实现\"模糊匹配\"式的上下文召回，根据当前任务需求检索语义相关的历史信息，适合需要智能联想和知识关联的场景，但向量化过程可能损失部分细节信息，且对嵌入模型质量依赖较高。\n关系数据库存储：采用传统关系型数据库（如PostgreSQL、MySQL）存储结构化的上下文信息，通过表结构组织对话轮次、任务ID、时间戳、角色等元数据，支持精确的SQL查询和复杂的关联检索，这种方式适合需要严格事务保证和复杂查询逻辑的场景，能够高效处理结构化数据和关系推理，但对非结构化文本的语义检索能力有限，通常需要结合全文索引或向量检索增强。\n文档数据库存储：使用文档型NoSQL数据库（如MongoDB、Elasticsearch）存储JSON格式的上下文文档，保留原始对话结构和嵌套关系，支持灵活的schema设计和全文检索，这种方式在保持数据完整性的同时提供较好的查询灵活性，适合半结构化数据和快速迭代的场景，Elasticsearch还提供强大的全文搜索和聚合分析能力，但在复杂关系查询上不如关系数据库。\n分层混合存储：根据上下文信息的访问频率和重要性采用分层存储策略，热数据（近期高频访问）保存在内存缓存（如Redis）中实现毫秒级访问，温数据（中期偶尔访问）存储在高速SSD数据库中，冷数据（长期归档）转移到对象存储（如S3）或归档系统中，这种方式平衡了访问性能和存储成本，通过自动数据迁移机制实现生命周期管理，适合大规模长期运行的Agent系统。\n图数据库存储：利用图数据库（如Neo4j、ArangoDB）将上下文信息建模为知识图谱，节点表示实体或概念，边表示关系或依赖，支持复杂的图遍历和关系推理查询，这种方式特别适合需要理解上下文间复杂关联关系的场景，如多轮对话中的指代消解、因果关系追踪、知识推理等，能够通过图算法发现隐含的信息关联，但图数据建模和维护成本较高。\n混合索引存储：结合多种索引技术构建混合检索系统，如同时使用向量索引（语义检索）、倒排索引（关键词检索）、时间索引（时序查询）和元数据索引（属性过滤），根据查询需求动态选择最优检索路径或融合多路检索结果，这种方式能够应对多样化的上下文召回需求，提供更全面和精确的检索能力，适合复杂的企业级Agent应用，但系统复杂度和维护成本相对较高。\n管理 1. 黑板模型 黑板模型（Blackboard Model）是一种经典的知识共享和协作架构，源于人工智能早期的专家系统研究，现在被广泛应用于多Agent系统的上下文管理中。其核心思想是模拟多个专家围绕一块\"黑板\"协作解决问题的场景：黑板作为共享的工作空间存储当前问题状态和中间结果，多个独立的知识源（Knowledge Sources）通过读取和更新黑板来协同工作，控制器负责协调各知识源的激活顺序。\n核心组件：\n黑板（Blackboard）：中央共享数据结构，存储问题求解过程中的所有信息，包括初始输入、中间推理结果、候选方案和最终解决方案。黑板通常采用分层结构组织信息，如原始数据层、特征提取层、假设层、决策层等，支持不同抽象级别的信息表示和访问。\n知识源（Knowledge Sources, KS）：独立的专家模块，每个知识源负责特定领域或特定类型的推理任务，如数据解析、模式识别、约束检查、方案生成等。知识源之间相互独立，不直接通信，只通过读写黑板进行间接协作。每个知识源包含触发条件（Condition）和执行动作（Action），当黑板状态满足其触发条件时被激活执行。\n控制器（Controller）：协调和调度机制，监控黑板状态变化，评估各知识源的触发条件，决定下一步激活哪个知识源，管理执行优先级和冲突解决。控制策略可以是规则驱动、优先级驱动、机会主义驱动或基于元知识的智能调度。\n工作流程：\nstateDiagram-v2 [*] --\u003e 初始化黑板 初始化黑板 --\u003e 控制器监控 控制器监控 --\u003e 评估知识源触发条件 评估知识源触发条件 --\u003e 选择待激活知识源 选择待激活知识源 --\u003e 知识源读取黑板 知识源读取黑板 --\u003e 知识源执行推理 知识源执行推理 --\u003e 知识源更新黑板 知识源更新黑板 --\u003e 检查问题是否解决 检查问题是否解决 --\u003e 控制器监控: 未解决 检查问题是否解决 --\u003e 输出最终结果: 已解决 输出最终结果 --\u003e [*] 在Agent上下文管理中的应用：\n多Agent协作的信息共享：黑板作为多个Agent之间的共享工作空间，每个Agent可以将自己的推理结果、发现的信息、生成的假设写入黑板，同时读取其他Agent贡献的内容，实现去中心化的信息交换，避免点对点通信的复杂性。\n异构知识的整合：不同Agent可能使用不同的推理方式（符号推理、神经网络、规则引擎等）和知识表示（文本、结构化数据、向量等），黑板提供统一的接口和数据格式，使异构Agent能够无缝协作。\n增量式问题求解：复杂任务的解决过程是渐进式的，黑板记录每一步的进展和中间状态，支持Agent从部分解逐步构建完整解，允许回溯和修正，适应动态变化的问题环境。\n机会主义推理：不需要预定义严格的执行顺序，控制器根据当前黑板状态和各Agent的能力动态决定下一步行动，哪个Agent有能力推进当前状态就激活哪个，实现灵活的任务编排。\n上下文分层管理：黑板的分层结构天然支持上下文的抽象层次管理，底层存储原始数据和详细信息，高层存储提炼后的知识和决策，Agent可以根据需要访问不同层次的上下文，实现精细化的上下文控制。\n优势：\n松耦合：知识源之间独立，易于添加、删除或替换Agent，系统扩展性强 透明性：所有信息集中在黑板上，便于监控、调试和解释推理过程 灵活性：支持动态调度和机会主义推理，适应复杂多变的任务 容错性：单个知识源失败不影响整体系统，其他知识源可以继续工作 挑战：\n并发控制：多个Agent同时读写黑板需要同步机制，避免竞态条件和数据不一致 调度复杂性：设计高效的控制策略需要平衡全局最优和计算开销 黑板膨胀：随着推理深入黑板信息量快速增长，需要结合上下文压缩和卸载技术 死锁风险：不当的触发条件设计可能导致没有知识源被激活或循环等待 现代实现方式：\n在现代Agent系统中，黑板模型常与向量数据库、消息队列、分布式缓存等技术结合实现：\n使用Redis或共享内存作为高性能黑板存储 采用发布-订阅模式实现黑板更新的事件通知 结合向量检索实现基于语义的黑板信息查询 使用版本控制和事务机制保证并发安全 引入优先级队列和智能调度算法优化控制策略 2. 类脑记忆 类脑记忆（Brain-inspired Memory）是借鉴人类大脑记忆机制设计的上下文管理方案，通过模拟人脑的多层次记忆系统、遗忘曲线、记忆巩固等认知过程，实现更加智能和高效的上下文管理。与传统的线性存储或简单缓存不同，类脑记忆强调记忆的动态性、层次性和自适应性，使Agent能够像人类一样选择性地记忆重要信息、遗忘无关细节、在需要时快速回忆相关经验。\n核心机制：\n多层次记忆结构：模拟人脑的感觉记忆、工作记忆（短期记忆）和长期记忆三级体系\n感觉记忆（Sensory Memory）：极短暂的原始输入缓存，保留最近几轮的完整对话或感知数据，容量小但保真度高，类似人脑对刚刚发生事件的即时印象，通常保持数秒到数分钟，用于快速响应和上下文连贯性\n工作记忆（Working Memory）：当前任务的活跃上下文，容量有限但访问速度快，存储正在处理的信息、中间推理步骤、临时变量和即时目标，对应Agent的\"注意力焦点\"，类似人脑在解决问题时能同时把握的信息量（约7±2个信息块）\n长期记忆（Long-term Memory）：持久化的知识和经验库，容量几乎无限但需要检索激活，分为显性记忆（事实、事件）和隐性记忆（技能、模式），通过编码和巩固过程从工作记忆转入，支持基于相关性和重要性的选择性提取\n记忆编码与巩固：模拟人脑将短期记忆转化为长期记忆的过程\n重要性评估：根据信息的任务相关性、情感强度（用户明确强调）、重复频率、新颖性等维度计算重要性分数，决定是否值得长期保存\n语义编码：将原始信息转换为语义表示（向量嵌入、知识图谱节点），提取关键概念和关系，去除冗余细节，便于后续的语义检索和关联\n巩固机制：通过定期回顾、关联强化、摘要提炼等方式巩固重要记忆，类似人脑在睡眠中的记忆整合过程，可以在Agent空闲时或任务间隙进行后台巩固\n自适应遗忘机制：模拟人脑的遗忘曲线（Ebbinghaus Forgetting Curve）\n时间衰减：记忆强度随时间指数衰减，越久未访问的记忆越容易被遗忘，但重要记忆衰减速度较慢\n主动遗忘：当存储空间不足时，优先遗忘低重要性、低访问频率、与当前任务无关的记忆，避免上下文膨胀\n遗忘保护：对于核心知识、用户明确要求记住的信息、高频访问的记忆设置保护机制，防止误删\n可恢复性：被遗忘的信息不是立即删除，而是降级到冷存储，必要时仍可恢复，类似人脑的\"提取失败\"而非\"完全丢失\"\n联想检索与激活扩散：模拟人脑通过联想回忆相关记忆的过程\n语义联想：基于向量相似度或知识图谱关系，从当前上下文触发相关记忆的检索，一个概念可以激活语义相近或有关联的其他记忆\n情景回忆：根据相似的任务场景、问题模式或上下文特征，检索历史中的类似经验，支持案例推理和经验迁移\n激活扩散：被激活的记忆节点会扩散激活相邻节点，形成记忆网络的局部激活区域，类似人脑的\"一个想法引发另一个想法\"\n记忆重构与更新：模拟人脑记忆的可塑性和重构特性\n动态更新：当新信息与已有记忆冲突时，更新或修正旧记忆，而非简单覆盖，保留版本历史以支持回溯\n记忆融合：将多次相似经验融合为更抽象的模式或规则，提取共性知识，类似人脑的概念形成过程\n重构偏差意识：记录记忆的来源、可信度和修改历史，避免因重构导致的记忆失真被当作原始事实\n工作流程：\nstateDiagram-v2 [*] --\u003e 感觉记忆接收输入 感觉记忆接收输入 --\u003e 工作记忆加载 工作记忆加载 --\u003e 评估重要性 评估重要性 --\u003e 编码为长期记忆: 重要信息 评估重要性 --\u003e 保持在工作记忆: 临时信息 编码为长期记忆 --\u003e 语义索引与关联 语义索引与关联 --\u003e 长期记忆存储 保持在工作记忆 --\u003e 任务处理 任务处理 --\u003e 联想检索长期记忆 联想检索长期记忆 --\u003e 激活相关记忆 激活相关记忆 --\u003e 加载到工作记忆 加载到工作记忆 --\u003e 任务处理 任务处理 --\u003e 工作记忆更新 工作记忆更新 --\u003e 检查容量 检查容量 --\u003e 卸载到长期记忆: 容量不足 检查容量 --\u003e 继续任务: 容量充足 卸载到长期记忆 --\u003e 编码为长期记忆 长期记忆存储 --\u003e 后台巩固 后台巩固 --\u003e 遗忘衰减处理 遗忘衰减处理 --\u003e 清理低价值记忆 清理低价值记忆 --\u003e 长期记忆存储 继续任务 --\u003e 判断任务完成 判断任务完成 --\u003e 感觉记忆接收输入: 未完成 判断任务完成 --\u003e 输出结果: 已完成 输出结果 --\u003e [*] 在Agent上下文管理中的应用：\n智能容量管理：通过多层次结构和自适应遗忘，自动平衡上下文窗口的有限容量与信息完整性需求，无需人工设置复杂的卸载规则\n经验积累与迁移：长期记忆中积累的历史经验可以在新任务中被联想检索，实现跨任务的知识迁移和快速适应\n上下文连贯性：工作记忆保持当前任务的活跃状态，感觉记忆提供即时历史，确保对话和推理的流畅性\n个性化记忆：针对不同用户或任务领域，形成差异化的长期记忆库，实现个性化的上下文管理\n抗干扰能力：通过重要性评估和选择性编码，过滤噪音信息，避免上下文中毒和干扰\n优势：\n自然性：符合人类认知习惯，易于理解和调试 自适应：根据任务特点和信息重要性动态调整记忆策略 高效性：多层次结构优化了访问速度和存储成本的平衡 鲁棒性：遗忘机制防止上下文膨胀，联想检索增强信息利用率 挑战：\n复杂性：实现完整的类脑记忆系统需要多个子模块协同工作 参数调优：遗忘曲线、重要性权重、巩固策略等参数需要针对具体应用场景调优 计算开销：后台巩固、联想检索、激活扩散等过程增加计算负担 评估困难：记忆质量和遗忘合理性难以量化评估 实现技术：\n向量数据库：存储长期记忆的语义表示，支持高效的联想检索（如Pinecone、Milvus） 图数据库：建模记忆间的关联关系，支持激活扩散和关系推理（如Neo4j） 优先级队列：管理工作记忆的容量和信息优先级 时间序列数据库：记录记忆的访问历史和衰减曲线（如InfluxDB） 强化学习：优化重要性评估和遗忘策略的参数 注意力机制：在工作记忆中动态聚焦最相关的信息片段 3. 解耦模块与动态扩展 解耦模块与动态扩展是 L2MAC（Large Language Model Agent with Multi-Agent Collaboration）等先进架构中突破上下文长度限制的核心方法，通过将复杂任务分解为多个独立的子任务模块，每个模块维护自己的局部上下文，避免单一 Agent 的上下文窗口被快速耗尽。这种方法的本质是\"分而治之\"——将原本需要在一个超长上下文中处理的信息，分散到多个专门化的模块中，通过模块间的协作和信息传递完成整体任务。\n核心思想：\n传统的单体 Agent 在处理复杂任务时，需要将所有相关信息（任务描述、历史对话、工具文档、中间结果等）都塞入一个上下文窗口，很快就会遇到长度限制。L2MAC 通过模块化解耦，将任务处理流程拆分为多个职责明确的模块，每个模块只需要关注自己负责的子任务和相关上下文，大大降低了单个上下文的负担。\nL2MAC 的模块化架构：\nstateDiagram-v2 [*] --\u003e 任务规划模块 任务规划模块 --\u003e 任务分解 任务分解 --\u003e 子任务队列 子任务队列 --\u003e 工具选择模块 工具选择模块 --\u003e 确定所需工具 确定所需工具 --\u003e 执行模块A 确定所需工具 --\u003e 执行模块B 确定所需工具 --\u003e 执行模块C 执行模块A --\u003e 局部上下文A 执行模块B --\u003e 局部上下文B 执行模块C --\u003e 局部上下文C 局部上下文A --\u003e 结果聚合模块 局部上下文B --\u003e 结果聚合模块 局部上下文C --\u003e 结果聚合模块 结果聚合模块 --\u003e 评估是否完成 评估是否完成 --\u003e 子任务队列: 需要继续 评估是否完成 --\u003e 最终输出: 已完成 最终输出 --\u003e [*] 关键技术机制：\n任务分解与模块分配（Task Decomposition and Module Assignment）：\n分层规划：高层规划模块将复杂任务分解为多个相对独立的子任务，每个子任务分配给专门的执行模块，规划模块只需维护任务依赖关系和执行顺序，不需要保留所有细节\n职责隔离：每个执行模块只负责特定类型的子任务（如数据检索、代码生成、结果验证等），只需加载与该子任务相关的上下文和工具，避免无关信息的干扰\n动态加载：根据当前子任务的需求，动态加载相应的工具文档、示例和知识，用完即卸载，而不是一开始就将所有可能用到的信息塞入上下文\n局部上下文管理（Local Context Management）：\n上下文隔离：每个执行模块维护独立的局部上下文，只包含当前子任务的输入、相关知识和执行历史，与其他模块的上下文物理隔离，互不干扰\n按需传递：模块间通过精简的消息传递接口交换信息，只传递必要的结果和状态，而不是完整的上下文历史，例如执行模块 A 完成后只向聚合模块传递结果摘要，而不是整个推理过程\n上下文重置：每个子任务完成后，其执行模块的上下文可以被清空或归档，为下一个子任务释放空间，实现上下文的循环利用\n增量式信息聚合（Incremental Information Aggregation）：\n流式聚合：结果聚合模块不是等所有子任务完成后一次性处理，而是采用流式聚合，每当一个子任务完成就立即整合其结果，保持聚合模块的上下文精简\n摘要提炼：对每个子任务的输出进行摘要提炼，提取关键信息后再加入全局上下文，过滤掉冗余细节，例如将一个 1000 token 的执行日志压缩为 50 token 的结果摘要\n分层存储：将详细的执行过程存储在外部（如向量数据库），全局上下文只保留高层摘要，需要时通过检索召回细节\n工具与知识的按需加载（On-demand Tool and Knowledge Loading）：\n工具分组：将大量工具按功能域分组（如文件操作、网络请求、数据处理等），每个执行模块只加载其需要的工具组，避免工具列表过长导致的上下文膨胀和工具选择混淆\n延迟加载：工具的详细文档和示例不在初始化时加载，而是在确定需要使用某个工具后才加载其详细说明，使用后立即卸载\n知识索引：将领域知识构建为可检索的知识库，执行模块根据子任务需求动态检索相关知识片段，而不是预先加载所有知识\n模块间的轻量通信（Lightweight Inter-Module Communication）：\n消息队列：使用消息队列或事件总线实现模块间的异步通信，发送方只需投递消息，不需要维护接收方的状态，降低耦合度\n标准化接口：定义统一的消息格式和接口协议，模块间交换的数据结构化且精简（如 JSON 格式的任务描述和结果），避免传递冗长的自然语言描述\n状态外部化：共享状态存储在外部状态管理器（如 Redis、数据库）中，模块通过状态 ID 引用，而不是在上下文中复制完整状态\n并行执行与上下文复用（Parallel Execution and Context Reuse）：\n并行模块：对于相互独立的子任务，可以启动多个执行模块并行处理，每个模块使用独立的上下文窗口，突破单一上下文的串行处理限制\n模块池：维护一个执行模块池，相同类型的子任务可以复用同一类模块实例，共享工具加载和初始化开销，但保持上下文隔离\n上下文模板：为常见的子任务类型预定义上下文模板，快速初始化执行模块，减少重复的上下文构建成本\n实际应用示例：\n假设一个复杂任务：“分析某公司最近三年的财报，生成投资建议报告”\n传统单体 Agent 的问题：\n需要在上下文中加载：任务描述、财报文档（可能很长）、分析工具文档、报告模板、历史对话等 上下文很快被耗尽，无法容纳完整的财报内容 工具选择时面对所有可用工具，容易混淆 L2MAC 的解耦方案：\n规划模块：分解为子任务 → ①获取财报 ②提取关键指标 ③趋势分析 ④生成报告 执行模块 1（财报获取）：局部上下文只包含：公司名称、年份范围、文档检索工具 → 输出：财报文档路径 执行模块 2（指标提取）：局部上下文只包含：财报文档、数据提取工具 → 输出：结构化指标数据（精简） 执行模块 3（趋势分析）：局部上下文只包含：指标数据、分析算法工具 → 输出：分析结论摘要 执行模块 4（报告生成）：局部上下文只包含：分析结论、报告模板、生成工具 → 输出：最终报告 聚合模块：只需维护各阶段的摘要结果，而不是完整的中间过程 优势：\n突破长度限制：每个模块的上下文需求远小于整体任务，可以处理原本无法在单一上下文中完成的复杂任务 提高准确性：模块专注于特定子任务，上下文更聚焦，减少无关信息的干扰，提高工具选择和推理的准确性 并行加速：独立子任务可以并行执行，缩短总体执行时间 可扩展性：新增功能只需添加新的执行模块，不影响现有模块 容错性：单个模块失败不会污染其他模块的上下文，可以独立重试或替换 挑战：\n任务分解质量：分解不当可能导致子任务间依赖复杂，反而增加协调成本 信息损失：模块间传递摘要可能丢失重要细节，需要平衡精简与完整性 协调开销：模块间通信和状态管理引入额外的系统复杂度 调试困难：问题可能出现在任何模块或模块间的交互，需要完善的监控和追踪机制 实现技术：\n多 Agent 框架：如 AutoGen、CrewAI、LangGraph 支持多 Agent 协作和模块化编排 消息队列：如 Celery、RabbitMQ 实现模块间的异步任务分发 状态管理：如 Redis、Memcached 存储共享状态和中间结果 工作流引擎：如 Airflow、Prefect 管理复杂的模块依赖和执行流程 向量数据库：如 Pinecone、Weaviate 存储和检索知识片段 分布式追踪：如 OpenTelemetry、Jaeger 追踪跨模块的执行链路 4. 领域定制化上下文优化 领域定制化上下文优化是针对特定应用领域（如医疗、法律、金融、代码生成等）的上下文管理策略，通过深度理解领域特性和任务模式，设计专门化的上下文组织、压缩和检索方案，相比通用方案能够显著提升上下文利用效率和任务完成质量。\n核心思想：\n不同领域的任务具有独特的信息结构、知识依赖和推理模式，通用的上下文管理方案往往无法充分利用这些领域特性。通过领域定制化，可以：\n识别领域中的关键信息类型和优先级 设计符合领域逻辑的上下文结构 利用领域知识进行智能压缩和扩展 优化领域特定的信息检索和推理路径 领域特性分析：\n医疗领域：\n信息特性：患者病史、检查结果、诊断标准、药物信息等结构化程度高 优先级：最新的检查结果、过敏史、当前用药等关键信息必须保留 推理模式：基于症状→检查→诊断→治疗的流程化推理 定制策略：将患者信息结构化为医疗记录模板，关键字段（过敏、慢性病）设置高优先级永不卸载，历史就诊记录按时间和相关性分层存储 法律领域：\n信息特性：法条、案例、证据材料、法律文书等，引用关系复杂 优先级：适用法条、关键证据、判例先例必须精确保留 推理模式：基于法条解释、案例类比、证据链推理 定制策略：构建法条知识图谱，通过引用关系检索相关法条，案例按相似度索引，证据材料按证明目标分类组织 代码生成领域：\n信息特性：代码库结构、API 文档、依赖关系、代码规范等 优先级：当前编辑文件的上下文、直接依赖的接口定义、相关的代码示例 推理模式：基于代码结构理解、API 调用、设计模式应用 定制策略：通过 AST 分析提取代码结构，按调用关系和模块依赖动态加载相关代码，使用代码摘要（函数签名、类定义）代替完整实现 金融领域：\n信息特性：市场数据、财务报表、交易规则、风险指标等，时效性强 优先级：最新市场数据、监管规则、风险阈值必须实时准确 推理模式：基于数据分析、趋势预测、风险评估 定制策略：时序数据按时间窗口聚合，历史数据存储统计特征而非原始值，规则和阈值参数化存储，通过参数引用而非重复描述 定制化技术方法：\n领域本体与知识图谱：\n构建领域特定的本体模型，定义核心概念、关系和约束 将领域知识组织为知识图谱，支持基于关系的上下文扩展和推理 上下文中只保留概念节点 ID 和关系，详细信息通过图查询按需获取 领域 DSL 与模板：\n设计领域特定语言（DSL）简洁表达领域概念，减少自然语言的冗余 预定义领域任务模板，标准化上下文结构，提高信息密度 例如医疗领域用结构化的 SOAP 笔记（Subjective, Objective, Assessment, Plan）代替自由文本 领域感知的压缩与摘要：\n训练领域特定的摘要模型，理解领域术语和重要性 基于领域知识的智能省略，例如法律文书中省略格式化条款，保留实质内容 利用领域缩写和标准化表达，例如医疗领域的疾病编码（ICD-10）、药物通用名 领域优化的检索策略：\n设计领域特定的检索索引，例如代码领域按符号和调用关系索引，法律领域按法条编号和案由索引 结合领域规则的混合检索，例如金融领域优先检索最新数据，医疗领域优先检索相关症状的诊断指南 利用领域知识进行查询扩展，例如检索\"高血压\"时自动扩展到相关的\"降压药\"、“心血管疾病” 领域特定的上下文分层：\n根据领域任务流程设计上下文层次，例如代码生成分为\"项目架构层\"、“模块接口层”、“函数实现层” 不同层次采用不同的保留策略和压缩比例 支持按层次的上下文切换和聚焦 优势：\n高效性：充分利用领域特性，上下文密度和相关性更高 准确性：符合领域逻辑的上下文组织提升推理质量 专业性：使用领域术语和标准，输出更符合专业要求 可解释性：基于领域知识的推理路径更易于专业人士理解和验证 挑战：\n开发成本：需要领域专家参与设计和验证 通用性损失：过度定制可能降低跨领域的适应能力 维护成本：领域知识和规则需要持续更新 冷启动问题：新领域缺乏足够的领域知识积累 实现技术：\n知识图谱：Neo4j、ArangoDB 存储领域本体和知识关系 领域模型：基于领域语料微调的 LLM 或专门的领域编码器 规则引擎：Drools、Easy Rules 管理领域规则和约束 领域数据库：针对特定领域优化的数据存储（如时序数据库 InfluxDB、医疗数据库 FHIR） 模板引擎：Jinja2、Mustache 管理领域模板和 DSL 多模型 协同方式 多智能体系统中的协同方式决定了 Agent 之间如何分配任务、传递信息和协调行动，主要有三种协同方式：\n1. 自由转交（Free Handoff） 自由转交是一种去中心化的协同方式，Agent 之间可以自主决定何时、向谁转交任务，无需预定义的流程或中央协调者。每个 Agent 根据当前任务状态、自身能力边界和其他 Agent 的专长，动态选择最合适的协作对象进行任务转交。这种方式灵活性最高，适合探索性和复杂多变的任务，但可能面临协调复杂、效率不确定和难以追踪的挑战。\n2. 工作流编排（Workflow Orchestration） 工作流编排是一种预定义、结构化的协同方式，通过事先设计好的工作流程图或规则，明确规定任务的执行顺序、Agent 的职责分工和信息流转路径。通常由一个中央编排器（Orchestrator）负责协调和调度各个 Agent 的执行，确保任务按照既定流程有序推进。这种方式可预测性强、易于管理和监控，适合标准化、重复性的业务流程，但灵活性较差，难以应对动态变化的情况。\n3. Plan \u0026 Execute 协同（Plan \u0026 Execute Collaboration） Plan \u0026 Execute 协同是一种结合了规划智能和执行灵活性的混合方式，先由规划 Agent 制定整体执行计划，然后由执行 Agent 按计划执行，执行过程中根据实际情况动态调整计划。规划 Agent 负责任务分解和宏观决策，执行 Agent 处理具体细节并反馈结果，形成计划-执行-反馈的闭环。这种方式在结构化和灵活性之间取得平衡，适合需要宏观规划和细节执行相结合的复杂多步骤任务，既有整体规划指导又能灵活应对变化。\n协同类型 多智能体系统中的协同类型反映了 Agent 之间的目标关系和互动模式，主要有三种协同类型：\n1. 合作（Cooperation） 合作是指多个 Agent 共享相同或一致的目标，通过明确的分工协作来共同完成任务。每个 Agent 发挥自己的专长负责特定子任务，彼此之间相互配合、信息共享，最终汇总各自的贡献形成完整解决方案。这种类型强调团队协作和优势互补，适合复杂任务的模块化分解，能够充分利用不同 Agent 的专业能力，但需要良好的协调机制来避免重复劳动和信息孤岛。\n2. 竞争（Competition） 竞争是指多个 Agent 针对同一问题独立提出不同的解决方案，通过辩论、评估或博弈的方式相互挑战和质疑，最终选出最优方案或综合各方观点。这种类型利用观点冲突和多样性来发现问题、纠正偏差、提升决策质量，类似于\"红队-蓝队\"对抗或多角度审视。竞争机制能够有效避免单一视角的盲点和群体思维陷阱，激发创新思维，但可能增加计算成本和决策时间，需要合理的评判标准来裁定优劣。\n3. 竞合（Coopetition） 竞合是合作与竞争的混合模式，Agent 之间在某些环节合作、在某些环节竞争，既有共同目标又存在局部利益冲突。例如多个 Agent 共同收集信息（合作），但各自独立提出解决方案并竞争最终采纳权（竞争），或者在迭代优化过程中交替进行协作改进和对抗验证。这种类型结合了合作的效率和竞争的质量保障，适合需要平衡多样性和一致性的复杂场景，能够在保持团队协同的同时激发个体创造力，但需要精心设计合作与竞争的边界和转换机制。\n通信结构 多智能体系统中的通信结构定义了 Agent 之间信息交换的拓扑关系和消息流转模式，主要有三种通信结构：\n1. 集中式（Centralized） 集中式通信结构采用中心节点（如协调者或编排器）作为信息枢纽，所有 Agent 之间的通信都通过中心节点中转和协调。中心节点负责接收各 Agent 的消息、进行任务分配、协调执行顺序、汇总结果，其他 Agent 不直接相互通信。这种结构管理简单、易于监控和全局优化，适合需要严格控制和集中决策的场景，但中心节点可能成为性能瓶颈和单点故障风险，且扩展性受限于中心节点的处理能力。\n2. 去中心化（Decentralized） 去中心化通信结构中没有固定的中心节点，Agent 之间采用点对点（P2P）的方式直接通信，每个 Agent 可以自主决定与谁交互、何时交互。Agent 之间地位平等，通过自组织和自协调完成任务，信息在网络中以分布式方式传播和处理。这种结构灵活性高、容错性强、无单点故障，适合动态变化和大规模分布式场景，但协调复杂度高，可能出现信息冗余或不一致，全局优化困难，需要设计良好的共识机制和冲突解决策略。\n3. 分层式（Hierarchical） 分层式通信结构将 Agent 组织为多层次的树状或金字塔结构，不同层级承担不同角色和职责。高层 Agent 负责宏观规划、战略决策和跨域协调，中层 Agent 负责任务分解和区域管理，底层 Agent 负责具体执行和数据采集。通信主要发生在相邻层级之间，上层向下层下达指令和目标，下层向上层反馈结果和状态。这种结构兼具集中式的可控性和去中心化的扩展性，适合大规模复杂系统和组织化任务，能够实现职责分离和抽象层次管理，但层级过多可能导致通信延迟和信息失真，需要平衡层次深度和通信效率。\n协同策略 多智能体系统中的协同策略决定了 Agent 如何进行决策和行动选择，主要有三种协同策略：\n1. 基于角色（Role-Based） 基于角色的协同策略为每个 Agent 分配明确的角色定位和职责范围，Agent 根据自己的角色来决定行为模式和交互方式。例如在软件开发团队中，可以设置产品经理、架构师、开发者、测试工程师等不同角色，每个角色有特定的专业知识、权限边界和工作流程。这种策略通过角色分工实现专业化和责任明确，便于管理和协调，适合职责清晰的结构化任务，但角色设计的合理性直接影响系统效能，且角色固化可能降低灵活性。\n2. 基于规则（Rule-Based） 基于规则的协同策略通过预定义的规则集来指导 Agent 的协同行为，规则明确规定在特定条件下应该采取什么行动、与谁协作、如何处理冲突。规则可以是简单的 if-then 条件语句，也可以是复杂的业务逻辑和约束条件。这种策略具有确定性和可解释性，行为可预测且易于审计，适合有明确规范和合规要求的领域（如金融、医疗），但规则的完备性和维护成本是挑战，难以应对规则未覆盖的新情况，且规则冲突时需要优先级机制。\n3. 基于模型（Model-Based） 基于模型的协同策略让 Agent 通过学习和推理来自主决定协同行为，而非依赖固定的角色或规则。Agent 可以使用机器学习模型（如强化学习）从历史经验中学习最优协作策略，或使用大语言模型进行情境理解和动态决策。这种策略具有高度的自适应性和智能性，能够处理复杂多变的场景，发现隐含的协作模式，适合开放性和不确定性高的任务，但模型的训练成本高、决策过程可解释性差，且需要大量数据和计算资源，模型质量直接决定协同效果。\n协同机制 多智能体系统中的协同机制决定了 Agent 协作关系的建立方式和时机，主要有两种协同机制：\n1. 静态协同（Static Collaboration） 静态协同机制在系统设计阶段就预定义好 Agent 之间的协作流程、交互关系和任务分配方案，运行时严格按照既定流程执行。协作图（包括 Agent 角色、连接关系、通信路径、执行顺序等）在启动前已经确定，不会因任务内容或执行状态而改变。这种机制具有高度的稳定性和可预测性，执行效率高且易于测试验证，适合流程固定、需求明确的标准化场景（如生产流水线、审批流程），但缺乏灵活性，难以应对任务变化和异常情况，扩展新功能需要重新设计整个协作流程。\n2. 动态协同（Dynamic Collaboration） 动态协同机制根据任务的具体需求和实时执行状态，在运行时动态创建和调整 Agent 之间的协作图。系统会分析任务特征、评估可用 Agent 的能力，实时决定需要哪些 Agent 参与、如何分工、以什么顺序执行，协作关系可以随着任务进展而演化。这种机制具有高度的灵活性和适应性，能够根据实际情况优化资源配置，适合复杂多变、需求不确定的场景（如应急响应、个性化服务），但动态决策增加了系统复杂度和计算开销，协作图的生成质量依赖于任务理解和 Agent 能力评估的准确性，且运行时的不确定性增加了调试和故障排查的难度。\n记忆系统 MEMGPT https://arxiv.org/abs/2310.08560\nMemGPT（Memory-enhanced GPT）是一个突破性的记忆系统，通过模拟操作系统的虚拟内存管理机制来突破大语言模型的上下文窗口限制。它将记忆分为主内存（main context）和外部存储（external context），通过智能的分页调度算法在有限的上下文窗口中动态加载最相关的记忆片段。MemGPT 引入了类似操作系统的内存管理指令集，Agent 可以显式地调用 core_memory_append、core_memory_replace、archival_memory_insert、archival_memory_search 等函数来管理自己的记忆，实现了对长期对话历史和大规模知识库的高效管理，使 Agent 能够在无限长的对话中保持连贯性和个性化。\nA-MEM https://arxiv.org/abs/2502.12110\nA-MEM（Adaptive Memory）是一种自适应的多层次记忆系统，核心特点是根据信息的访问模式和重要性动态调整记忆的存储层级和保留策略。它采用分层存储架构（热-温-冷三层），结合访问频率、时间衰减和语义相关性等多维度指标，自动将记忆在不同存储层之间迁移。A-MEM 引入了记忆强化机制，被频繁访问或被 Agent 标记为重要的记忆会得到强化，衰减速度变慢并优先保留，而长期未使用的记忆则逐渐降级到冷存储甚至被遗忘。这种自适应机制使 Agent 能够像人类一样选择性地记住重要信息，自动平衡记忆容量和信息完整性。\nMemory OS of AI Agent https://arxiv.org/abs/2506.06326\nMemory OS 是一个为 AI Agent 设计的完整记忆操作系统，提供了统一的记忆管理抽象层和丰富的记忆操作接口。它将记忆管理从 Agent 的核心逻辑中解耦出来，提供类似操作系统的系统调用接口，包括记忆的创建、读取、更新、删除、检索、索引、压缩、归档等全生命周期管理功能。Memory OS 支持多种记忆类型（情景记忆、语义记忆、程序记忆）和存储后端（向量数据库、图数据库、关系数据库），提供统一的查询语言和事务保证，使不同的 Agent 应用能够基于标准化的记忆接口进行开发，大幅降低记忆系统的实现复杂度和提高可移植性。\nM3-Agent https://arxiv.org/pdf/2508.09736\nM3-Agent（Multi-Modal Multi-Memory Agent）是一个支持多模态和多记忆类型的综合记忆系统，特别强调跨模态信息的统一记忆和关联。它能够同时处理和记忆文本、图像、音频、视频等多种模态的信息，通过多模态编码器将不同模态统一映射到共享的语义空间，实现跨模态的记忆检索和推理。M3-Agent 区分了不同类型的记忆（如事实记忆、经验记忆、技能记忆、社交记忆），为每种记忆类型设计专门的存储结构和检索策略，并通过记忆融合机制将多源多模态的记忆片段整合为连贯的知识表示，使 Agent 能够在复杂的多模态交互场景中保持丰富的记忆能力。\nAgent KB https://arxiv.org/pdf/2507.06229\nAgent KB（Agent Knowledge Base）是一个面向 Agent 的知识库系统，专注于结构化知识的组织和高效检索。与传统记忆系统侧重对话历史和经验不同，Agent KB 强调领域知识的系统化管理，采用知识图谱作为核心数据结构，将实体、概念、关系、规则等知识元素组织为可推理的图结构。它提供了知识的增量更新、版本管理、一致性校验、冲突解决等企业级功能，支持基于图遍历的复杂查询和多跳推理，并能够与外部知识源（如维基百科、企业数据库）进行知识同步和融合。Agent KB 使 Agent 能够基于结构化知识进行精确推理和可解释决策，特别适合知识密集型的专业领域应用。\n","wordCount":"1370","inLanguage":"en","datePublished":"2025-10-28T17:45:42+08:00","dateModified":"2025-10-28T17:45:42+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://genluo.github.io/my-blog/posts/agent/"},"publisher":{"@type":"Organization","name":"Genluo","logo":{"@type":"ImageObject","url":"https://genluo.github.io/my-blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://genluo.github.io/my-blog/ accesskey=h title="Genluo (Alt + H)">Genluo</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://genluo.github.io/my-blog/archives/ title=归档><span>归档</span></a></li><li><a href=https://genluo.github.io/my-blog/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=https://genluo.github.io/my-blog/tags/ title=标签><span>标签</span></a></li><li><a href=https://genluo.github.io/my-blog/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://genluo.github.io/my-blog/>Home</a>&nbsp;»&nbsp;<a href=https://genluo.github.io/my-blog/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Agent 技术调研</h1><div class=post-description>Agent 相关技术调研，按照自己的层级思路，具体的介绍是AI生成的</div><div class=post-meta><span title='2025-10-28 17:45:42 +0800 +0800'>October 28, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1370 words</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#agent-%e5%86%85%e5%ae%b9 aria-label="Agent 内容">Agent 内容</a><ul><li><a href=#%e5%b7%a5%e4%bd%9c%e6%b5%81%e4%bb%8b%e7%bb%8d aria-label=工作流介绍>工作流介绍</a><ul><li><a href=#%e9%a1%ba%e5%ba%8f%e6%89%a7%e8%a1%8c%e5%9e%8b aria-label=顺序执行型>顺序执行型</a><ul><li><a href=#1-react aria-label="1. ReAct">1. ReAct</a></li><li><a href=#2-plan--execute aria-label="2. Plan & Execute">2. Plan & Execute</a></li><li><a href=#3-%e6%b5%81%e6%b0%b4%e5%bc%8f aria-label="3. 流水式">3. 流水式</a></li><li><a href=#4-%e6%8f%90%e7%a4%ba%e9%93%be aria-label="4. 提示链">4. 提示链</a></li></ul></li><li><a href=#%e5%8d%8f%e4%bd%9c%e4%bc%98%e5%8c%96%e5%9e%8b aria-label=协作优化型>协作优化型</a><ul><li><a href=#1-%e8%87%aa%e5%8d%8f%e5%95%86 aria-label="1. 自协商">1. 自协商</a></li><li><a href=#2-%e8%af%84%e4%bc%b0%e4%bc%98%e5%8c%96 aria-label="2. 评估优化">2. 评估优化</a></li><li><a href=#3-%e5%a4%9a%e6%99%ba%e8%83%bd%e4%bd%93%e5%8d%8f%e4%bd%9c aria-label="3. 多智能体协作">3. 多智能体协作</a></li><li><a href=#4-%e5%88%86%e5%b1%82%e8%a7%84%e5%88%92 aria-label="4. 分层规划">4. 分层规划</a></li></ul></li><li><a href=#%e5%8a%a8%e6%80%81%e7%bc%96%e6%8e%92%e5%9e%8b aria-label=动态编排型>动态编排型</a><ul><li><a href=#1-%e5%8a%a8%e6%80%81%e7%bc%96%e6%8e%92 aria-label="1. 动态编排">1. 动态编排</a></li><li><a href=#2-%e8%87%aa%e6%bc%94%e5%8c%96 aria-label="2. 自演化">2. 自演化</a></li><li><a href=#3-%e6%b7%b7%e5%90%88%e6%a8%a1%e5%bc%8f aria-label="3. 混合模式">3. 混合模式</a></li><li><a href=#4-%e8%b7%af%e7%94%b1 aria-label="4. 路由">4. 路由</a></li><li><a href=#5-%e5%b9%b6%e8%a1%8c%e5%8c%96 aria-label="5. 并行化">5. 并行化</a></li><li><a href=#6-%e5%8d%8f%e8%b0%83%e8%80%85-%e5%b7%a5%e4%bd%9c%e8%80%85 aria-label="6. 协调者-工作者">6. 协调者-工作者</a></li></ul></li></ul></li><li><a href=#agent-%e7%9b%b8%e5%85%b3%e6%8a%80%e6%9c%af aria-label="Agent 相关技术">Agent 相关技术</a><ul><li><a href=#%e4%b8%8a%e4%b8%8b%e6%96%87 aria-label=上下文>上下文</a><ul><li><a href=#%e9%97%ae%e9%a2%98 aria-label=问题>问题</a><ul><li><a href=#1-%e4%b8%8a%e4%b8%8b%e6%96%87%e4%b8%ad%e6%af%92 aria-label="1. 上下文中毒">1. 上下文中毒</a></li><li><a href=#2-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%b9%b2%e6%89%b0 aria-label="2. 上下文干扰">2. 上下文干扰</a></li><li><a href=#3-%e4%b8%8a%e4%b8%8b%e6%96%87%e6%b7%b7%e6%b7%86 aria-label="3. 上下文混淆">3. 上下文混淆</a></li><li><a href=#4-%e4%b8%8a%e4%b8%8b%e6%96%87%e9%a3%98%e7%a7%bb aria-label="4. 上下文飘移">4. 上下文飘移</a></li></ul></li><li><a href=#%e6%8a%80%e6%9c%af aria-label=技术>技术</a><ul><li><a href=#1-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%8e%8b%e7%bc%a9 aria-label="1. 上下文压缩">1. 上下文压缩</a></li><li><a href=#2-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%8d%b8%e8%bd%bd aria-label="2. 上下文卸载">2. 上下文卸载</a></li><li><a href=#3-%e4%b8%8a%e4%b8%8b%e6%96%87%e5%ad%98%e5%82%a8 aria-label="3. 上下文存储">3. 上下文存储</a></li></ul></li><li><a href=#%e7%ae%a1%e7%90%86 aria-label=管理>管理</a><ul><li><a href=#1-%e9%bb%91%e6%9d%bf%e6%a8%a1%e5%9e%8b aria-label="1. 黑板模型">1. 黑板模型</a></li><li><a href=#2-%e7%b1%bb%e8%84%91%e8%ae%b0%e5%bf%86 aria-label="2. 类脑记忆">2. 类脑记忆</a></li><li><a href=#3-%e8%a7%a3%e8%80%a6%e6%a8%a1%e5%9d%97%e4%b8%8e%e5%8a%a8%e6%80%81%e6%89%a9%e5%b1%95 aria-label="3. 解耦模块与动态扩展">3. 解耦模块与动态扩展</a></li><li><a href=#4-%e9%a2%86%e5%9f%9f%e5%ae%9a%e5%88%b6%e5%8c%96%e4%b8%8a%e4%b8%8b%e6%96%87%e4%bc%98%e5%8c%96 aria-label="4. 领域定制化上下文优化">4. 领域定制化上下文优化</a></li></ul></li></ul></li><li><a href=#%e5%a4%9a%e6%a8%a1%e5%9e%8b aria-label=多模型>多模型</a><ul><li><a href=#%e5%8d%8f%e5%90%8c%e6%96%b9%e5%bc%8f aria-label=协同方式>协同方式</a><ul><li><a href=#1-%e8%87%aa%e7%94%b1%e8%bd%ac%e4%ba%a4free-handoff aria-label="1. 自由转交（Free Handoff）">1. 自由转交（Free Handoff）</a></li><li><a href=#2-%e5%b7%a5%e4%bd%9c%e6%b5%81%e7%bc%96%e6%8e%92workflow-orchestration aria-label="2. 工作流编排（Workflow Orchestration）">2. 工作流编排（Workflow Orchestration）</a></li><li><a href=#3-plan--execute-%e5%8d%8f%e5%90%8cplan--execute-collaboration aria-label="3. Plan & Execute 协同（Plan & Execute Collaboration）">3. Plan & Execute 协同（Plan & Execute Collaboration）</a></li></ul></li><li><a href=#%e5%8d%8f%e5%90%8c%e7%b1%bb%e5%9e%8b aria-label=协同类型>协同类型</a><ul><li><a href=#1-%e5%90%88%e4%bd%9ccooperation aria-label="1. 合作（Cooperation）">1. 合作（Cooperation）</a></li><li><a href=#2-%e7%ab%9e%e4%ba%89competition aria-label="2. 竞争（Competition）">2. 竞争（Competition）</a></li><li><a href=#3-%e7%ab%9e%e5%90%88coopetition aria-label="3. 竞合（Coopetition）">3. 竞合（Coopetition）</a></li></ul></li><li><a href=#%e9%80%9a%e4%bf%a1%e7%bb%93%e6%9e%84 aria-label=通信结构>通信结构</a><ul><li><a href=#1-%e9%9b%86%e4%b8%ad%e5%bc%8fcentralized aria-label="1. 集中式（Centralized）">1. 集中式（Centralized）</a></li><li><a href=#2-%e5%8e%bb%e4%b8%ad%e5%bf%83%e5%8c%96decentralized aria-label="2. 去中心化（Decentralized）">2. 去中心化（Decentralized）</a></li><li><a href=#3-%e5%88%86%e5%b1%82%e5%bc%8fhierarchical aria-label="3. 分层式（Hierarchical）">3. 分层式（Hierarchical）</a></li></ul></li><li><a href=#%e5%8d%8f%e5%90%8c%e7%ad%96%e7%95%a5 aria-label=协同策略>协同策略</a><ul><li><a href=#1-%e5%9f%ba%e4%ba%8e%e8%a7%92%e8%89%b2role-based aria-label="1. 基于角色（Role-Based）">1. 基于角色（Role-Based）</a></li><li><a href=#2-%e5%9f%ba%e4%ba%8e%e8%a7%84%e5%88%99rule-based aria-label="2. 基于规则（Rule-Based）">2. 基于规则（Rule-Based）</a></li><li><a href=#3-%e5%9f%ba%e4%ba%8e%e6%a8%a1%e5%9e%8bmodel-based aria-label="3. 基于模型（Model-Based）">3. 基于模型（Model-Based）</a></li></ul></li><li><a href=#%e5%8d%8f%e5%90%8c%e6%9c%ba%e5%88%b6 aria-label=协同机制>协同机制</a><ul><li><a href=#1-%e9%9d%99%e6%80%81%e5%8d%8f%e5%90%8cstatic-collaboration aria-label="1. 静态协同（Static Collaboration）">1. 静态协同（Static Collaboration）</a></li><li><a href=#2-%e5%8a%a8%e6%80%81%e5%8d%8f%e5%90%8cdynamic-collaboration aria-label="2. 动态协同（Dynamic Collaboration）">2. 动态协同（Dynamic Collaboration）</a></li></ul></li></ul></li><li><a href=#%e8%ae%b0%e5%bf%86%e7%b3%bb%e7%bb%9f aria-label=记忆系统>记忆系统</a><ul><li><a href=#memgpt aria-label=MEMGPT>MEMGPT</a></li><li><a href=#a-mem aria-label=A-MEM>A-MEM</a></li><li><a href=#memory-os-of-ai-agent aria-label="Memory OS of AI Agent">Memory OS of AI Agent</a></li><li><a href=#m3-agent aria-label=M3-Agent>M3-Agent</a></li><li><a href=#agent-kb aria-label="Agent KB">Agent KB</a></li></ul></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h2 id=agent-内容><code>Agent</code> 内容<a hidden class=anchor aria-hidden=true href=#agent-内容>#</a></h2><p>整个 <code>Agent</code> 相关技术拆为两个大的部分进行介绍，一个是对应的工作流，一个是对应的 <code>Agent</code> 开发相关技术</p><h3 id=工作流介绍>工作流介绍<a hidden class=anchor aria-hidden=true href=#工作流介绍>#</a></h3><ul><li>顺序执行型：ReAct、Plan & Execute、流水式、提示链</li><li>协作优化型：自协商、评估优化、多智能体协作、分层规划</li><li>动态编排型：动态编排、自演化、混合模式、路由、并行化、协调者-工作者</li></ul><h4 id=顺序执行型>顺序执行型<a hidden class=anchor aria-hidden=true href=#顺序执行型>#</a></h4><h5 id=1-react>1. ReAct<a hidden class=anchor aria-hidden=true href=#1-react>#</a></h5><p>通过推理（Reasoning）和行动（Acting）交替循环的方式，让Agent在思考和执行工具之间迭代，直到完成任务。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 接收任务
    接收任务 --&gt; 推理思考
    推理思考 --&gt; 判断是否需要行动
    判断是否需要行动 --&gt; 执行工具: 需要行动
    判断是否需要行动 --&gt; 生成答案: 无需行动
    执行工具 --&gt; 观察结果
    观察结果 --&gt; 推理思考
    生成答案 --&gt; [*]
</code></pre><h5 id=2-plan--execute>2. Plan & Execute<a hidden class=anchor aria-hidden=true href=#2-plan--execute>#</a></h5><p>先制定完整的执行计划，然后按照计划逐步执行各个步骤，适合复杂任务的分解与执行。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 接收任务
    接收任务 --&gt; 规划阶段
    规划阶段 --&gt; 生成执行计划
    生成执行计划 --&gt; 执行步骤1
    执行步骤1 --&gt; 执行步骤2
    执行步骤2 --&gt; 执行步骤N
    执行步骤N --&gt; 检查完成状态
    检查完成状态 --&gt; 返回结果: 已完成
    检查完成状态 --&gt; 重新规划: 需调整
    重新规划 --&gt; 生成执行计划
    返回结果 --&gt; [*]
</code></pre><h5 id=3-流水式>3. 流水式<a hidden class=anchor aria-hidden=true href=#3-流水式>#</a></h5><p>将任务按固定顺序分配到多个专门的Agent，每个Agent处理特定环节后传递给下一个，形成处理流水线。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; Agent1
    Agent1 --&gt; Agent2: 输出1
    Agent2 --&gt; Agent3: 输出2
    Agent3 --&gt; Agent4: 输出3
    Agent4 --&gt; 最终输出
    最终输出 --&gt; [*]
</code></pre><h5 id=4-提示链>4. 提示链<a hidden class=anchor aria-hidden=true href=#4-提示链>#</a></h5><p>通过将复杂任务拆解为一系列简单的提示步骤，每步的输出作为下一步的输入，形成提示链式传递。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; Prompt1
    Prompt1 --&gt; 生成中间结果1
    生成中间结果1 --&gt; Prompt2
    Prompt2 --&gt; 生成中间结果2
    生成中间结果2 --&gt; Prompt3
    Prompt3 --&gt; 生成中间结果3
    生成中间结果3 --&gt; PromptN
    PromptN --&gt; 最终结果
    最终结果 --&gt; [*]
</code></pre><h4 id=协作优化型>协作优化型<a hidden class=anchor aria-hidden=true href=#协作优化型>#</a></h4><h5 id=1-自协商>1. 自协商<a hidden class=anchor aria-hidden=true href=#1-自协商>#</a></h5><p>Agent通过自我对话或多角色辩论的方式，从不同视角审视问题，通过协商达成更优的解决方案。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 接收任务
    接收任务 --&gt; 生成初始方案
    生成初始方案 --&gt; 角色A提出观点
    角色A提出观点 --&gt; 角色B反驳质疑
    角色B反驳质疑 --&gt; 角色A回应改进
    角色A回应改进 --&gt; 评估是否达成共识
    评估是否达成共识 --&gt; 角色B反驳质疑: 未达成
    评估是否达成共识 --&gt; 输出协商结果: 已达成
    输出协商结果 --&gt; [*]
</code></pre><h5 id=2-评估优化>2. 评估优化<a hidden class=anchor aria-hidden=true href=#2-评估优化>#</a></h5><p>通过独立的评估者Agent对执行结果进行评分和反馈，执行者根据反馈持续优化，直到达到质量标准。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 执行者生成初始输出
    执行者生成初始输出 --&gt; 评估者评分
    评估者评分 --&gt; 评估者提供改进建议
    评估者提供改进建议 --&gt; 判断质量
    判断质量 --&gt; 执行者优化改进: 未达标
    判断质量 --&gt; 输出最终结果: 已达标
    执行者优化改进 --&gt; 评估者评分
    输出最终结果 --&gt; [*]
</code></pre><h5 id=3-多智能体协作>3. 多智能体协作<a hidden class=anchor aria-hidden=true href=#3-多智能体协作>#</a></h5><p>多个具有不同专长的 <code>Agent</code> 协同工作，通过信息共享和任务分配，发挥各自优势完成复杂任务。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 任务分配器
    任务分配器 --&gt; Agent1专家
    任务分配器 --&gt; Agent2专家
    任务分配器 --&gt; Agent3专家
    Agent1专家 --&gt; 共享信息池
    Agent2专家 --&gt; 共享信息池
    Agent3专家 --&gt; 共享信息池
    共享信息池 --&gt; 协调者
    协调者 --&gt; 判断是否完成
    判断是否完成 --&gt; 分配后续任务: 未完成
    判断是否完成 --&gt; 结果汇总: 已完成
    分配后续任务 --&gt; Agent1专家
    分配后续任务 --&gt; Agent2专家
    分配后续任务 --&gt; Agent3专家
    结果汇总 --&gt; [*]
</code></pre><h5 id=4-分层规划>4. 分层规划<a hidden class=anchor aria-hidden=true href=#4-分层规划>#</a></h5><p>采用层次化的规划策略，高层Agent负责宏观规划和目标分解，低层Agent负责具体执行，实现复杂任务的结构化管理。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 高层规划Agent
    高层规划Agent --&gt; 制定战略目标
    制定战略目标 --&gt; 分解为子目标
    分解为子目标 --&gt; 中层规划Agent
    中层规划Agent --&gt; 制定执行计划
    制定执行计划 --&gt; 分配具体任务
    分配具体任务 --&gt; 低层执行Agent
    低层执行Agent --&gt; 执行具体操作
    执行具体操作 --&gt; 向上反馈结果
    向上反馈结果 --&gt; 中层规划Agent
    中层规划Agent --&gt; 评估进度
    评估进度 --&gt; 高层规划Agent: 汇报总体进展
    高层规划Agent --&gt; 判断目标完成
    判断目标完成 --&gt; 调整战略: 需调整
    判断目标完成 --&gt; 输出最终结果: 已完成
    调整战略 --&gt; 分解为子目标
    输出最终结果 --&gt; [*]
</code></pre><h4 id=动态编排型>动态编排型<a hidden class=anchor aria-hidden=true href=#动态编排型>#</a></h4><h5 id=1-动态编排>1. 动态编排<a hidden class=anchor aria-hidden=true href=#1-动态编排>#</a></h5><p>根据任务执行过程中的实时状态和反馈，动态调整工作流程和 <code>Agent</code> 组合，实现灵活的任务编排。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 接收任务
    接收任务 --&gt; 分析任务特征
    分析任务特征 --&gt; 动态生成工作流
    动态生成工作流 --&gt; 执行当前步骤
    执行当前步骤 --&gt; 评估执行状态
    评估执行状态 --&gt; 判断是否需要调整
    判断是否需要调整 --&gt; 重新编排工作流: 需要调整
    判断是否需要调整 --&gt; 继续执行: 无需调整
    重新编排工作流 --&gt; 执行当前步骤
    继续执行 --&gt; 判断任务完成
    判断任务完成 --&gt; 执行当前步骤: 未完成
    判断任务完成 --&gt; 输出结果: 已完成
    输出结果 --&gt; [*]
</code></pre><h5 id=2-自演化>2. 自演化<a hidden class=anchor aria-hidden=true href=#2-自演化>#</a></h5><p><code>Agent</code> 通过学习历史经验和反馈，不断优化自身的提示词、工具选择和决策策略，实现自我进化。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 初始化Agent
    初始化Agent --&gt; 执行任务
    执行任务 --&gt; 收集执行数据
    收集执行数据 --&gt; 分析成功失败案例
    分析成功失败案例 --&gt; 提取经验模式
    提取经验模式 --&gt; 更新策略库
    更新策略库 --&gt; 优化提示词
    优化提示词 --&gt; 调整工具选择
    调整工具选择 --&gt; 升级Agent版本
    升级Agent版本 --&gt; 验证新版本
    验证新版本 --&gt; 执行任务: 持续进化
    验证新版本 --&gt; 回滚版本: 效果变差
    回滚版本 --&gt; 执行任务
</code></pre><h5 id=3-混合模式>3. 混合模式<a hidden class=anchor aria-hidden=true href=#3-混合模式>#</a></h5><p>结合多种工作流模式的优势，针对不同子任务采用最适合的执行模式，形成混合工作流架构。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 任务分析
    任务分析 --&gt; 子任务1
    任务分析 --&gt; 子任务2
    任务分析 --&gt; 子任务3
    子任务1 --&gt; ReAct模式
    子任务2 --&gt; 流水式模式
    子任务3 --&gt; 多智能体协作模式
    ReAct模式 --&gt; 结果汇总
    流水式模式 --&gt; 结果汇总
    多智能体协作模式 --&gt; 结果汇总
    结果汇总 --&gt; 整合输出
    整合输出 --&gt; [*]
</code></pre><h5 id=4-路由>4. 路由<a hidden class=anchor aria-hidden=true href=#4-路由>#</a></h5><p>根据任务类型、复杂度或领域特征，智能路由到最适合的 <code>Agent</code> 或处理流程，实现任务的精准分发。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 接收任务
    接收任务 --&gt; 路由分析器
    路由分析器 --&gt; 判断任务类型
    判断任务类型 --&gt; 简单查询Agent: 简单查询
    判断任务类型 --&gt; 复杂推理Agent: 复杂推理
    判断任务类型 --&gt; 代码生成Agent: 代码任务
    判断任务类型 --&gt; 数据分析Agent: 数据分析
    简单查询Agent --&gt; 返回结果
    复杂推理Agent --&gt; 返回结果
    代码生成Agent --&gt; 返回结果
    数据分析Agent --&gt; 返回结果
    返回结果 --&gt; [*]
</code></pre><h5 id=5-并行化>5. 并行化<a hidden class=anchor aria-hidden=true href=#5-并行化>#</a></h5><p>将独立的子任务或步骤并行分配给多个 <code>Agent</code> 同时执行，显著提升整体执行效率。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 任务分解
    任务分解 --&gt; 并行执行
    state 并行执行 {
        [*] --&gt; Agent1
        [*] --&gt; Agent2
        [*] --&gt; Agent3
        [*] --&gt; Agent4
        Agent1 --&gt; [*]
        Agent2 --&gt; [*]
        Agent3 --&gt; [*]
        Agent4 --&gt; [*]
    }
    并行执行 --&gt; 等待所有任务完成
    等待所有任务完成 --&gt; 结果聚合
    结果聚合 --&gt; 最终输出
    最终输出 --&gt; [*]
</code></pre><h5 id=6-协调者-工作者>6. 协调者-工作者<a hidden class=anchor aria-hidden=true href=#6-协调者-工作者>#</a></h5><p>协调者 <code>Agent</code> 负责任务分配、进度监控和结果整合，工作者 <code>Agent</code> 专注于执行具体任务，实现职责分离。</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 协调者接收任务
    协调者接收任务 --&gt; 协调者分析任务
    协调者分析任务 --&gt; 协调者分配任务
    协调者分配任务 --&gt; 工作者1执行
    协调者分配任务 --&gt; 工作者2执行
    协调者分配任务 --&gt; 工作者3执行
    工作者1执行 --&gt; 工作者1报告进度
    工作者2执行 --&gt; 工作者2报告进度
    工作者3执行 --&gt; 工作者3报告进度
    工作者1报告进度 --&gt; 协调者监控
    工作者2报告进度 --&gt; 协调者监控
    工作者3报告进度 --&gt; 协调者监控
    协调者监控 --&gt; 判断完成状态
    判断完成状态 --&gt; 协调者调整策略: 需要调整
    判断完成状态 --&gt; 协调者整合结果: 全部完成
    协调者调整策略 --&gt; 协调者分配任务
    协调者整合结果 --&gt; 输出最终结果
    输出最终结果 --&gt; [*]
</code></pre><h3 id=agent-相关技术><code>Agent</code> 相关技术<a hidden class=anchor aria-hidden=true href=#agent-相关技术>#</a></h3><h4 id=上下文>上下文<a hidden class=anchor aria-hidden=true href=#上下文>#</a></h4><h5 id=问题>问题<a hidden class=anchor aria-hidden=true href=#问题>#</a></h5><h6 id=1-上下文中毒>1. 上下文中毒<a hidden class=anchor aria-hidden=true href=#1-上下文中毒>#</a></h6><p>指错误信息、幻觉内容或过时数据被写入 <code>Agent</code> 的上下文后，被模型反复引用、强化，最终导致整个推理链条崩坏的现象。一旦错误信息进入上下文，模型会将其视为可信事实，在后续推理中不断基于这些错误前提进行演绎，形成错误累积和放大效应。</p><p><strong>解决思路</strong>：建立信息源可信度评估机制，对外部输入进行验证；引入事实核查层，对关键信息进行交叉验证；使用时间戳标记上下文信息的时效性，定期更新过时数据；实施上下文质量监控，检测推理链中的逻辑矛盾；采用多路径验证策略，通过不同推理路径交叉印证结果的正确性。</p><h6 id=2-上下文干扰>2. 上下文干扰<a hidden class=anchor aria-hidden=true href=#2-上下文干扰>#</a></h6><p>指上下文中存在过多无关或冗余信息，干扰模型对关键信息的识别和处理。在长对话或复杂任务中，早期的无关细节可能分散模型注意力，降低对当前任务重点的把握能力。</p><p><strong>解决思路</strong>：采用上下文压缩技术提取关键信息摘要；实施滑动窗口机制只保留最近的相关对话；使用相关性评分算法筛选高价值信息；引入注意力引导提示词明确指向当前任务重点；定期进行上下文清理，移除过时或无关内容。</p><h6 id=3-上下文混淆>3. 上下文混淆<a hidden class=anchor aria-hidden=true href=#3-上下文混淆>#</a></h6><p>指多个任务或对话线程的信息在上下文中交织，导致模型无法正确区分和关联相关信息。当处理多轮嵌套对话或并行任务时，模型可能混淆不同场景的参数、状态或目标。在 <code>MCP</code>（Model Context Protocol）场景中，当可用工具数量过多时，模型难以准确匹配工具功能与任务需求，容易选错工具或混淆相似工具的使用场景。</p><p><strong>解决思路</strong>：为不同任务或对话线程分配独立的上下文空间；使用明确的标识符或分隔标记区分不同场景；采用命名空间机制隔离不同任务的状态和变量；建立上下文索引系统快速定位相关信息；在提示词中显式声明当前操作的任务范围；对于 <code>MCP</code> 工具管理，采用分层分类组织工具，根据任务类型动态加载相关工具子集，使用语义化的工具描述和示例增强工具识别度。</p><h6 id=4-上下文飘移>4. 上下文飘移<a hidden class=anchor aria-hidden=true href=#4-上下文飘移>#</a></h6><p>指随着交互轮次增加，上下文逐渐偏离原始任务目标或主题的现象。模型可能在长对话中逐步丢失初始意图，转向相关但非核心的话题，导致最终输出与用户预期不符。</p><p><strong>解决思路</strong>：在上下文中持久化保留原始任务目标作为锚点；定期回顾和重申初始意图；设置偏离度检测机制，当话题偏离超过阈值时触发提醒；使用目标导向的提示词模板引导对话回归主线；建立任务完成度评估体系，确保每个交互步骤与最终目标的关联性。</p><h5 id=技术>技术<a hidden class=anchor aria-hidden=true href=#技术>#</a></h5><h6 id=1-上下文压缩>1. 上下文压缩<a hidden class=anchor aria-hidden=true href=#1-上下文压缩>#</a></h6><p>上下文压缩是应对长文本处理和上下文窗口限制的关键技术，主要包括三种方式：</p><p><strong>过滤式压缩（删除）</strong>：通过相关性评分、关键词匹配或语义相似度计算，筛选出与当前任务最相关的信息片段，过滤掉冗余或低价值内容，保留核心上下文，适用于需要快速降低上下文长度的场景，优势在于实现简单、效率高，但可能丢失潜在有用的边缘信息。</p><p><strong>提炼式压缩（浓缩）</strong>：利用摘要模型或大语言模型对原始上下文进行语义提炼，将长文本浓缩为简洁的摘要或关键点列表，保留核心语义和逻辑关系，适用于需要保持信息完整性和连贯性的场景，能够在大幅压缩的同时保持语义质量，但依赖模型的理解和生成能力，可能引入摘要偏差。</p><p><strong>结构化压缩</strong>：将非结构化的上下文信息转换为结构化表示，如知识图谱、表格、JSON对象或向量嵌入，通过结构化组织实现信息的高效存储和检索，适用于需要频繁查询和复用上下文的场景，优势在于支持精确检索和关系推理，但需要额外的结构化处理步骤，对信息的结构化质量要求较高。</p><h6 id=2-上下文卸载>2. 上下文卸载<a hidden class=anchor aria-hidden=true href=#2-上下文卸载>#</a></h6><p>上下文卸载是将暂时不需要的上下文信息从活跃工作区转移到外部存储的技术，以释放有限的上下文窗口空间，主要包括以下几种方式：</p><p><strong>基于时间的卸载（LRU策略）</strong>：采用最近最少使用（Least Recently Used）算法，根据上下文信息的访问时间戳，优先卸载最久未被访问的内容，这种方式假设最近使用的信息更可能在近期再次被需要，实现简单且适用于大多数场景，但可能误卸载重要但暂时未访问的关键信息，适合处理时序性强的对话和任务。</p><p><strong>基于优先级的卸载</strong>：为上下文中的不同信息片段分配优先级权重，如任务目标、用户明确指令、关键决策节点等赋予高优先级，而中间推理过程、临时计算结果等赋予低优先级，当上下文空间不足时优先卸载低优先级内容，这种方式能够保护核心信息不被误删，但需要建立合理的优先级评估机制，适用于复杂任务和长期对话场景。</p><p><strong>基于语义相关性的卸载</strong>：通过计算上下文片段与当前任务的语义相似度或相关性评分，卸载与当前任务关联度低的历史信息，利用向量嵌入和语义检索技术动态评估信息价值，这种方式能够智能识别真正无关的内容，但计算开销较大且依赖语义理解质量，适合需要精确保留相关上下文的知识密集型任务。</p><p><strong>分层卸载策略</strong>：将上下文信息按照抽象层次分为不同级别，如原始对话记录、中间推理步骤、提炼后的结论和元信息等，优先卸载低层次的原始数据，保留高层次的精炼信息和摘要，这种方式在节省空间的同时保持信息的可追溯性，支持必要时从外部存储重新加载详细内容，适用于需要平衡详细度和效率的长期运行Agent。</p><p><strong>触发式卸载</strong>：设置上下文使用率的阈值监控机制，当上下文占用率达到预设警戒线（如80%）时自动触发卸载流程，或在任务阶段切换、对话主题转移等关键节点主动进行上下文清理，这种方式结合了被动响应和主动管理，能够在保证性能的同时避免上下文溢出，适合动态变化的交互场景和多任务并行处理。</p><h6 id=3-上下文存储>3. 上下文存储<a hidden class=anchor aria-hidden=true href=#3-上下文存储>#</a></h6><p>上下文存储是将卸载的上下文信息持久化保存并支持高效检索的技术，确保历史信息在需要时能够快速恢复到工作区，主要包括以下几种方式：</p><p><strong>向量数据库存储</strong>：将上下文信息通过嵌入模型转换为高维向量表示，存储在专门的向量数据库（如Pinecone、Milvus、Weaviate）中，支持基于语义相似度的快速检索，这种方式能够实现"模糊匹配"式的上下文召回，根据当前任务需求检索语义相关的历史信息，适合需要智能联想和知识关联的场景，但向量化过程可能损失部分细节信息，且对嵌入模型质量依赖较高。</p><p><strong>关系数据库存储</strong>：采用传统关系型数据库（如PostgreSQL、MySQL）存储结构化的上下文信息，通过表结构组织对话轮次、任务ID、时间戳、角色等元数据，支持精确的SQL查询和复杂的关联检索，这种方式适合需要严格事务保证和复杂查询逻辑的场景，能够高效处理结构化数据和关系推理，但对非结构化文本的语义检索能力有限，通常需要结合全文索引或向量检索增强。</p><p><strong>文档数据库存储</strong>：使用文档型NoSQL数据库（如MongoDB、Elasticsearch）存储JSON格式的上下文文档，保留原始对话结构和嵌套关系，支持灵活的schema设计和全文检索，这种方式在保持数据完整性的同时提供较好的查询灵活性，适合半结构化数据和快速迭代的场景，Elasticsearch还提供强大的全文搜索和聚合分析能力，但在复杂关系查询上不如关系数据库。</p><p><strong>分层混合存储</strong>：根据上下文信息的访问频率和重要性采用分层存储策略，热数据（近期高频访问）保存在内存缓存（如Redis）中实现毫秒级访问，温数据（中期偶尔访问）存储在高速SSD数据库中，冷数据（长期归档）转移到对象存储（如S3）或归档系统中，这种方式平衡了访问性能和存储成本，通过自动数据迁移机制实现生命周期管理，适合大规模长期运行的Agent系统。</p><p><strong>图数据库存储</strong>：利用图数据库（如Neo4j、ArangoDB）将上下文信息建模为知识图谱，节点表示实体或概念，边表示关系或依赖，支持复杂的图遍历和关系推理查询，这种方式特别适合需要理解上下文间复杂关联关系的场景，如多轮对话中的指代消解、因果关系追踪、知识推理等，能够通过图算法发现隐含的信息关联，但图数据建模和维护成本较高。</p><p><strong>混合索引存储</strong>：结合多种索引技术构建混合检索系统，如同时使用向量索引（语义检索）、倒排索引（关键词检索）、时间索引（时序查询）和元数据索引（属性过滤），根据查询需求动态选择最优检索路径或融合多路检索结果，这种方式能够应对多样化的上下文召回需求，提供更全面和精确的检索能力，适合复杂的企业级Agent应用，但系统复杂度和维护成本相对较高。</p><h5 id=管理>管理<a hidden class=anchor aria-hidden=true href=#管理>#</a></h5><h6 id=1-黑板模型>1. 黑板模型<a hidden class=anchor aria-hidden=true href=#1-黑板模型>#</a></h6><p>黑板模型（Blackboard Model）是一种经典的知识共享和协作架构，源于人工智能早期的专家系统研究，现在被广泛应用于多Agent系统的上下文管理中。其核心思想是模拟多个专家围绕一块"黑板"协作解决问题的场景：黑板作为共享的工作空间存储当前问题状态和中间结果，多个独立的知识源（Knowledge Sources）通过读取和更新黑板来协同工作，控制器负责协调各知识源的激活顺序。</p><p><strong>核心组件</strong>：</p><ol><li><p><strong>黑板（Blackboard）</strong>：中央共享数据结构，存储问题求解过程中的所有信息，包括初始输入、中间推理结果、候选方案和最终解决方案。黑板通常采用分层结构组织信息，如原始数据层、特征提取层、假设层、决策层等，支持不同抽象级别的信息表示和访问。</p></li><li><p><strong>知识源（Knowledge Sources, KS）</strong>：独立的专家模块，每个知识源负责特定领域或特定类型的推理任务，如数据解析、模式识别、约束检查、方案生成等。知识源之间相互独立，不直接通信，只通过读写黑板进行间接协作。每个知识源包含触发条件（Condition）和执行动作（Action），当黑板状态满足其触发条件时被激活执行。</p></li><li><p><strong>控制器（Controller）</strong>：协调和调度机制，监控黑板状态变化，评估各知识源的触发条件，决定下一步激活哪个知识源，管理执行优先级和冲突解决。控制策略可以是规则驱动、优先级驱动、机会主义驱动或基于元知识的智能调度。</p></li></ol><p><strong>工作流程</strong>：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 初始化黑板
    初始化黑板 --&gt; 控制器监控
    控制器监控 --&gt; 评估知识源触发条件
    评估知识源触发条件 --&gt; 选择待激活知识源
    选择待激活知识源 --&gt; 知识源读取黑板
    知识源读取黑板 --&gt; 知识源执行推理
    知识源执行推理 --&gt; 知识源更新黑板
    知识源更新黑板 --&gt; 检查问题是否解决
    检查问题是否解决 --&gt; 控制器监控: 未解决
    检查问题是否解决 --&gt; 输出最终结果: 已解决
    输出最终结果 --&gt; [*]
</code></pre><p><strong>在Agent上下文管理中的应用</strong>：</p><ol><li><p><strong>多Agent协作的信息共享</strong>：黑板作为多个Agent之间的共享工作空间，每个Agent可以将自己的推理结果、发现的信息、生成的假设写入黑板，同时读取其他Agent贡献的内容，实现去中心化的信息交换，避免点对点通信的复杂性。</p></li><li><p><strong>异构知识的整合</strong>：不同Agent可能使用不同的推理方式（符号推理、神经网络、规则引擎等）和知识表示（文本、结构化数据、向量等），黑板提供统一的接口和数据格式，使异构Agent能够无缝协作。</p></li><li><p><strong>增量式问题求解</strong>：复杂任务的解决过程是渐进式的，黑板记录每一步的进展和中间状态，支持Agent从部分解逐步构建完整解，允许回溯和修正，适应动态变化的问题环境。</p></li><li><p><strong>机会主义推理</strong>：不需要预定义严格的执行顺序，控制器根据当前黑板状态和各Agent的能力动态决定下一步行动，哪个Agent有能力推进当前状态就激活哪个，实现灵活的任务编排。</p></li><li><p><strong>上下文分层管理</strong>：黑板的分层结构天然支持上下文的抽象层次管理，底层存储原始数据和详细信息，高层存储提炼后的知识和决策，Agent可以根据需要访问不同层次的上下文，实现精细化的上下文控制。</p></li></ol><p><strong>优势</strong>：</p><ul><li><strong>松耦合</strong>：知识源之间独立，易于添加、删除或替换Agent，系统扩展性强</li><li><strong>透明性</strong>：所有信息集中在黑板上，便于监控、调试和解释推理过程</li><li><strong>灵活性</strong>：支持动态调度和机会主义推理，适应复杂多变的任务</li><li><strong>容错性</strong>：单个知识源失败不影响整体系统，其他知识源可以继续工作</li></ul><p><strong>挑战</strong>：</p><ul><li><strong>并发控制</strong>：多个Agent同时读写黑板需要同步机制，避免竞态条件和数据不一致</li><li><strong>调度复杂性</strong>：设计高效的控制策略需要平衡全局最优和计算开销</li><li><strong>黑板膨胀</strong>：随着推理深入黑板信息量快速增长，需要结合上下文压缩和卸载技术</li><li><strong>死锁风险</strong>：不当的触发条件设计可能导致没有知识源被激活或循环等待</li></ul><p><strong>现代实现方式</strong>：</p><p>在现代Agent系统中，黑板模型常与向量数据库、消息队列、分布式缓存等技术结合实现：</p><ul><li>使用Redis或共享内存作为高性能黑板存储</li><li>采用发布-订阅模式实现黑板更新的事件通知</li><li>结合向量检索实现基于语义的黑板信息查询</li><li>使用版本控制和事务机制保证并发安全</li><li>引入优先级队列和智能调度算法优化控制策略</li></ul><h6 id=2-类脑记忆>2. 类脑记忆<a hidden class=anchor aria-hidden=true href=#2-类脑记忆>#</a></h6><p>类脑记忆（Brain-inspired Memory）是借鉴人类大脑记忆机制设计的上下文管理方案，通过模拟人脑的多层次记忆系统、遗忘曲线、记忆巩固等认知过程，实现更加智能和高效的上下文管理。与传统的线性存储或简单缓存不同，类脑记忆强调记忆的动态性、层次性和自适应性，使Agent能够像人类一样选择性地记忆重要信息、遗忘无关细节、在需要时快速回忆相关经验。</p><p><strong>核心机制</strong>：</p><ol><li><p><strong>多层次记忆结构</strong>：模拟人脑的感觉记忆、工作记忆（短期记忆）和长期记忆三级体系</p><ul><li><p><strong>感觉记忆（Sensory Memory）</strong>：极短暂的原始输入缓存，保留最近几轮的完整对话或感知数据，容量小但保真度高，类似人脑对刚刚发生事件的即时印象，通常保持数秒到数分钟，用于快速响应和上下文连贯性</p></li><li><p><strong>工作记忆（Working Memory）</strong>：当前任务的活跃上下文，容量有限但访问速度快，存储正在处理的信息、中间推理步骤、临时变量和即时目标，对应Agent的"注意力焦点"，类似人脑在解决问题时能同时把握的信息量（约7±2个信息块）</p></li><li><p><strong>长期记忆（Long-term Memory）</strong>：持久化的知识和经验库，容量几乎无限但需要检索激活，分为显性记忆（事实、事件）和隐性记忆（技能、模式），通过编码和巩固过程从工作记忆转入，支持基于相关性和重要性的选择性提取</p></li></ul></li><li><p><strong>记忆编码与巩固</strong>：模拟人脑将短期记忆转化为长期记忆的过程</p><ul><li><p><strong>重要性评估</strong>：根据信息的任务相关性、情感强度（用户明确强调）、重复频率、新颖性等维度计算重要性分数，决定是否值得长期保存</p></li><li><p><strong>语义编码</strong>：将原始信息转换为语义表示（向量嵌入、知识图谱节点），提取关键概念和关系，去除冗余细节，便于后续的语义检索和关联</p></li><li><p><strong>巩固机制</strong>：通过定期回顾、关联强化、摘要提炼等方式巩固重要记忆，类似人脑在睡眠中的记忆整合过程，可以在Agent空闲时或任务间隙进行后台巩固</p></li></ul></li><li><p><strong>自适应遗忘机制</strong>：模拟人脑的遗忘曲线（Ebbinghaus Forgetting Curve）</p><ul><li><p><strong>时间衰减</strong>：记忆强度随时间指数衰减，越久未访问的记忆越容易被遗忘，但重要记忆衰减速度较慢</p></li><li><p><strong>主动遗忘</strong>：当存储空间不足时，优先遗忘低重要性、低访问频率、与当前任务无关的记忆，避免上下文膨胀</p></li><li><p><strong>遗忘保护</strong>：对于核心知识、用户明确要求记住的信息、高频访问的记忆设置保护机制，防止误删</p></li><li><p><strong>可恢复性</strong>：被遗忘的信息不是立即删除，而是降级到冷存储，必要时仍可恢复，类似人脑的"提取失败"而非"完全丢失"</p></li></ul></li><li><p><strong>联想检索与激活扩散</strong>：模拟人脑通过联想回忆相关记忆的过程</p><ul><li><p><strong>语义联想</strong>：基于向量相似度或知识图谱关系，从当前上下文触发相关记忆的检索，一个概念可以激活语义相近或有关联的其他记忆</p></li><li><p><strong>情景回忆</strong>：根据相似的任务场景、问题模式或上下文特征，检索历史中的类似经验，支持案例推理和经验迁移</p></li><li><p><strong>激活扩散</strong>：被激活的记忆节点会扩散激活相邻节点，形成记忆网络的局部激活区域，类似人脑的"一个想法引发另一个想法"</p></li></ul></li><li><p><strong>记忆重构与更新</strong>：模拟人脑记忆的可塑性和重构特性</p><ul><li><p><strong>动态更新</strong>：当新信息与已有记忆冲突时，更新或修正旧记忆，而非简单覆盖，保留版本历史以支持回溯</p></li><li><p><strong>记忆融合</strong>：将多次相似经验融合为更抽象的模式或规则，提取共性知识，类似人脑的概念形成过程</p></li><li><p><strong>重构偏差意识</strong>：记录记忆的来源、可信度和修改历史，避免因重构导致的记忆失真被当作原始事实</p></li></ul></li></ol><p><strong>工作流程</strong>：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 感觉记忆接收输入
    感觉记忆接收输入 --&gt; 工作记忆加载
    工作记忆加载 --&gt; 评估重要性
    评估重要性 --&gt; 编码为长期记忆: 重要信息
    评估重要性 --&gt; 保持在工作记忆: 临时信息
    编码为长期记忆 --&gt; 语义索引与关联
    语义索引与关联 --&gt; 长期记忆存储
    保持在工作记忆 --&gt; 任务处理
    任务处理 --&gt; 联想检索长期记忆
    联想检索长期记忆 --&gt; 激活相关记忆
    激活相关记忆 --&gt; 加载到工作记忆
    加载到工作记忆 --&gt; 任务处理
    任务处理 --&gt; 工作记忆更新
    工作记忆更新 --&gt; 检查容量
    检查容量 --&gt; 卸载到长期记忆: 容量不足
    检查容量 --&gt; 继续任务: 容量充足
    卸载到长期记忆 --&gt; 编码为长期记忆
    长期记忆存储 --&gt; 后台巩固
    后台巩固 --&gt; 遗忘衰减处理
    遗忘衰减处理 --&gt; 清理低价值记忆
    清理低价值记忆 --&gt; 长期记忆存储
    继续任务 --&gt; 判断任务完成
    判断任务完成 --&gt; 感觉记忆接收输入: 未完成
    判断任务完成 --&gt; 输出结果: 已完成
    输出结果 --&gt; [*]
</code></pre><p><strong>在Agent上下文管理中的应用</strong>：</p><ol><li><p><strong>智能容量管理</strong>：通过多层次结构和自适应遗忘，自动平衡上下文窗口的有限容量与信息完整性需求，无需人工设置复杂的卸载规则</p></li><li><p><strong>经验积累与迁移</strong>：长期记忆中积累的历史经验可以在新任务中被联想检索，实现跨任务的知识迁移和快速适应</p></li><li><p><strong>上下文连贯性</strong>：工作记忆保持当前任务的活跃状态，感觉记忆提供即时历史，确保对话和推理的流畅性</p></li><li><p><strong>个性化记忆</strong>：针对不同用户或任务领域，形成差异化的长期记忆库，实现个性化的上下文管理</p></li><li><p><strong>抗干扰能力</strong>：通过重要性评估和选择性编码，过滤噪音信息，避免上下文中毒和干扰</p></li></ol><p><strong>优势</strong>：</p><ul><li><strong>自然性</strong>：符合人类认知习惯，易于理解和调试</li><li><strong>自适应</strong>：根据任务特点和信息重要性动态调整记忆策略</li><li><strong>高效性</strong>：多层次结构优化了访问速度和存储成本的平衡</li><li><strong>鲁棒性</strong>：遗忘机制防止上下文膨胀，联想检索增强信息利用率</li></ul><p><strong>挑战</strong>：</p><ul><li><strong>复杂性</strong>：实现完整的类脑记忆系统需要多个子模块协同工作</li><li><strong>参数调优</strong>：遗忘曲线、重要性权重、巩固策略等参数需要针对具体应用场景调优</li><li><strong>计算开销</strong>：后台巩固、联想检索、激活扩散等过程增加计算负担</li><li><strong>评估困难</strong>：记忆质量和遗忘合理性难以量化评估</li></ul><p><strong>实现技术</strong>：</p><ul><li><strong>向量数据库</strong>：存储长期记忆的语义表示，支持高效的联想检索（如Pinecone、Milvus）</li><li><strong>图数据库</strong>：建模记忆间的关联关系，支持激活扩散和关系推理（如Neo4j）</li><li><strong>优先级队列</strong>：管理工作记忆的容量和信息优先级</li><li><strong>时间序列数据库</strong>：记录记忆的访问历史和衰减曲线（如InfluxDB）</li><li><strong>强化学习</strong>：优化重要性评估和遗忘策略的参数</li><li><strong>注意力机制</strong>：在工作记忆中动态聚焦最相关的信息片段</li></ul><h6 id=3-解耦模块与动态扩展>3. 解耦模块与动态扩展<a hidden class=anchor aria-hidden=true href=#3-解耦模块与动态扩展>#</a></h6><p>解耦模块与动态扩展是 L2MAC（Large Language Model Agent with Multi-Agent Collaboration）等先进架构中突破上下文长度限制的核心方法，通过将复杂任务分解为多个独立的子任务模块，每个模块维护自己的局部上下文，避免单一 Agent 的上下文窗口被快速耗尽。这种方法的本质是"分而治之"——将原本需要在一个超长上下文中处理的信息，分散到多个专门化的模块中，通过模块间的协作和信息传递完成整体任务。</p><p><strong>核心思想</strong>：</p><p>传统的单体 Agent 在处理复杂任务时，需要将所有相关信息（任务描述、历史对话、工具文档、中间结果等）都塞入一个上下文窗口，很快就会遇到长度限制。L2MAC 通过模块化解耦，将任务处理流程拆分为多个职责明确的模块，每个模块只需要关注自己负责的子任务和相关上下文，大大降低了单个上下文的负担。</p><p><strong>L2MAC 的模块化架构</strong>：</p><pre tabindex=0><code class=language-mermaid data-lang=mermaid>stateDiagram-v2
    [*] --&gt; 任务规划模块
    任务规划模块 --&gt; 任务分解
    任务分解 --&gt; 子任务队列
    子任务队列 --&gt; 工具选择模块
    工具选择模块 --&gt; 确定所需工具
    确定所需工具 --&gt; 执行模块A
    确定所需工具 --&gt; 执行模块B
    确定所需工具 --&gt; 执行模块C
    执行模块A --&gt; 局部上下文A
    执行模块B --&gt; 局部上下文B
    执行模块C --&gt; 局部上下文C
    局部上下文A --&gt; 结果聚合模块
    局部上下文B --&gt; 结果聚合模块
    局部上下文C --&gt; 结果聚合模块
    结果聚合模块 --&gt; 评估是否完成
    评估是否完成 --&gt; 子任务队列: 需要继续
    评估是否完成 --&gt; 最终输出: 已完成
    最终输出 --&gt; [*]
</code></pre><p><strong>关键技术机制</strong>：</p><ol><li><p><strong>任务分解与模块分配（Task Decomposition and Module Assignment）</strong>：</p><ul><li><p><strong>分层规划</strong>：高层规划模块将复杂任务分解为多个相对独立的子任务，每个子任务分配给专门的执行模块，规划模块只需维护任务依赖关系和执行顺序，不需要保留所有细节</p></li><li><p><strong>职责隔离</strong>：每个执行模块只负责特定类型的子任务（如数据检索、代码生成、结果验证等），只需加载与该子任务相关的上下文和工具，避免无关信息的干扰</p></li><li><p><strong>动态加载</strong>：根据当前子任务的需求，动态加载相应的工具文档、示例和知识，用完即卸载，而不是一开始就将所有可能用到的信息塞入上下文</p></li></ul></li><li><p><strong>局部上下文管理（Local Context Management）</strong>：</p><ul><li><p><strong>上下文隔离</strong>：每个执行模块维护独立的局部上下文，只包含当前子任务的输入、相关知识和执行历史，与其他模块的上下文物理隔离，互不干扰</p></li><li><p><strong>按需传递</strong>：模块间通过精简的消息传递接口交换信息，只传递必要的结果和状态，而不是完整的上下文历史，例如执行模块 A 完成后只向聚合模块传递结果摘要，而不是整个推理过程</p></li><li><p><strong>上下文重置</strong>：每个子任务完成后，其执行模块的上下文可以被清空或归档，为下一个子任务释放空间，实现上下文的循环利用</p></li></ul></li><li><p><strong>增量式信息聚合（Incremental Information Aggregation）</strong>：</p><ul><li><p><strong>流式聚合</strong>：结果聚合模块不是等所有子任务完成后一次性处理，而是采用流式聚合，每当一个子任务完成就立即整合其结果，保持聚合模块的上下文精简</p></li><li><p><strong>摘要提炼</strong>：对每个子任务的输出进行摘要提炼，提取关键信息后再加入全局上下文，过滤掉冗余细节，例如将一个 1000 token 的执行日志压缩为 50 token 的结果摘要</p></li><li><p><strong>分层存储</strong>：将详细的执行过程存储在外部（如向量数据库），全局上下文只保留高层摘要，需要时通过检索召回细节</p></li></ul></li><li><p><strong>工具与知识的按需加载（On-demand Tool and Knowledge Loading）</strong>：</p><ul><li><p><strong>工具分组</strong>：将大量工具按功能域分组（如文件操作、网络请求、数据处理等），每个执行模块只加载其需要的工具组，避免工具列表过长导致的上下文膨胀和工具选择混淆</p></li><li><p><strong>延迟加载</strong>：工具的详细文档和示例不在初始化时加载，而是在确定需要使用某个工具后才加载其详细说明，使用后立即卸载</p></li><li><p><strong>知识索引</strong>：将领域知识构建为可检索的知识库，执行模块根据子任务需求动态检索相关知识片段，而不是预先加载所有知识</p></li></ul></li><li><p><strong>模块间的轻量通信（Lightweight Inter-Module Communication）</strong>：</p><ul><li><p><strong>消息队列</strong>：使用消息队列或事件总线实现模块间的异步通信，发送方只需投递消息，不需要维护接收方的状态，降低耦合度</p></li><li><p><strong>标准化接口</strong>：定义统一的消息格式和接口协议，模块间交换的数据结构化且精简（如 JSON 格式的任务描述和结果），避免传递冗长的自然语言描述</p></li><li><p><strong>状态外部化</strong>：共享状态存储在外部状态管理器（如 Redis、数据库）中，模块通过状态 ID 引用，而不是在上下文中复制完整状态</p></li></ul></li><li><p><strong>并行执行与上下文复用（Parallel Execution and Context Reuse）</strong>：</p><ul><li><p><strong>并行模块</strong>：对于相互独立的子任务，可以启动多个执行模块并行处理，每个模块使用独立的上下文窗口，突破单一上下文的串行处理限制</p></li><li><p><strong>模块池</strong>：维护一个执行模块池，相同类型的子任务可以复用同一类模块实例，共享工具加载和初始化开销，但保持上下文隔离</p></li><li><p><strong>上下文模板</strong>：为常见的子任务类型预定义上下文模板，快速初始化执行模块，减少重复的上下文构建成本</p></li></ul></li></ol><p><strong>实际应用示例</strong>：</p><p>假设一个复杂任务：&ldquo;分析某公司最近三年的财报，生成投资建议报告&rdquo;</p><p><strong>传统单体 Agent 的问题</strong>：</p><ul><li>需要在上下文中加载：任务描述、财报文档（可能很长）、分析工具文档、报告模板、历史对话等</li><li>上下文很快被耗尽，无法容纳完整的财报内容</li><li>工具选择时面对所有可用工具，容易混淆</li></ul><p><strong>L2MAC 的解耦方案</strong>：</p><ol><li><strong>规划模块</strong>：分解为子任务 → ①获取财报 ②提取关键指标 ③趋势分析 ④生成报告</li><li><strong>执行模块 1（财报获取）</strong>：局部上下文只包含：公司名称、年份范围、文档检索工具 → 输出：财报文档路径</li><li><strong>执行模块 2（指标提取）</strong>：局部上下文只包含：财报文档、数据提取工具 → 输出：结构化指标数据（精简）</li><li><strong>执行模块 3（趋势分析）</strong>：局部上下文只包含：指标数据、分析算法工具 → 输出：分析结论摘要</li><li><strong>执行模块 4（报告生成）</strong>：局部上下文只包含：分析结论、报告模板、生成工具 → 输出：最终报告</li><li><strong>聚合模块</strong>：只需维护各阶段的摘要结果，而不是完整的中间过程</li></ol><p><strong>优势</strong>：</p><ul><li><strong>突破长度限制</strong>：每个模块的上下文需求远小于整体任务，可以处理原本无法在单一上下文中完成的复杂任务</li><li><strong>提高准确性</strong>：模块专注于特定子任务，上下文更聚焦，减少无关信息的干扰，提高工具选择和推理的准确性</li><li><strong>并行加速</strong>：独立子任务可以并行执行，缩短总体执行时间</li><li><strong>可扩展性</strong>：新增功能只需添加新的执行模块，不影响现有模块</li><li><strong>容错性</strong>：单个模块失败不会污染其他模块的上下文，可以独立重试或替换</li></ul><p><strong>挑战</strong>：</p><ul><li><strong>任务分解质量</strong>：分解不当可能导致子任务间依赖复杂，反而增加协调成本</li><li><strong>信息损失</strong>：模块间传递摘要可能丢失重要细节，需要平衡精简与完整性</li><li><strong>协调开销</strong>：模块间通信和状态管理引入额外的系统复杂度</li><li><strong>调试困难</strong>：问题可能出现在任何模块或模块间的交互，需要完善的监控和追踪机制</li></ul><p><strong>实现技术</strong>：</p><ul><li><strong>多 Agent 框架</strong>：如 AutoGen、CrewAI、LangGraph 支持多 Agent 协作和模块化编排</li><li><strong>消息队列</strong>：如 Celery、RabbitMQ 实现模块间的异步任务分发</li><li><strong>状态管理</strong>：如 Redis、Memcached 存储共享状态和中间结果</li><li><strong>工作流引擎</strong>：如 Airflow、Prefect 管理复杂的模块依赖和执行流程</li><li><strong>向量数据库</strong>：如 Pinecone、Weaviate 存储和检索知识片段</li><li><strong>分布式追踪</strong>：如 OpenTelemetry、Jaeger 追踪跨模块的执行链路</li></ul><h6 id=4-领域定制化上下文优化>4. 领域定制化上下文优化<a hidden class=anchor aria-hidden=true href=#4-领域定制化上下文优化>#</a></h6><p>领域定制化上下文优化是针对特定应用领域（如医疗、法律、金融、代码生成等）的上下文管理策略，通过深度理解领域特性和任务模式，设计专门化的上下文组织、压缩和检索方案，相比通用方案能够显著提升上下文利用效率和任务完成质量。</p><p><strong>核心思想</strong>：</p><p>不同领域的任务具有独特的信息结构、知识依赖和推理模式，通用的上下文管理方案往往无法充分利用这些领域特性。通过领域定制化，可以：</p><ul><li>识别领域中的关键信息类型和优先级</li><li>设计符合领域逻辑的上下文结构</li><li>利用领域知识进行智能压缩和扩展</li><li>优化领域特定的信息检索和推理路径</li></ul><p><strong>领域特性分析</strong>：</p><ol><li><p><strong>医疗领域</strong>：</p><ul><li><strong>信息特性</strong>：患者病史、检查结果、诊断标准、药物信息等结构化程度高</li><li><strong>优先级</strong>：最新的检查结果、过敏史、当前用药等关键信息必须保留</li><li><strong>推理模式</strong>：基于症状→检查→诊断→治疗的流程化推理</li><li><strong>定制策略</strong>：将患者信息结构化为医疗记录模板，关键字段（过敏、慢性病）设置高优先级永不卸载，历史就诊记录按时间和相关性分层存储</li></ul></li><li><p><strong>法律领域</strong>：</p><ul><li><strong>信息特性</strong>：法条、案例、证据材料、法律文书等，引用关系复杂</li><li><strong>优先级</strong>：适用法条、关键证据、判例先例必须精确保留</li><li><strong>推理模式</strong>：基于法条解释、案例类比、证据链推理</li><li><strong>定制策略</strong>：构建法条知识图谱，通过引用关系检索相关法条，案例按相似度索引，证据材料按证明目标分类组织</li></ul></li><li><p><strong>代码生成领域</strong>：</p><ul><li><strong>信息特性</strong>：代码库结构、API 文档、依赖关系、代码规范等</li><li><strong>优先级</strong>：当前编辑文件的上下文、直接依赖的接口定义、相关的代码示例</li><li><strong>推理模式</strong>：基于代码结构理解、API 调用、设计模式应用</li><li><strong>定制策略</strong>：通过 AST 分析提取代码结构，按调用关系和模块依赖动态加载相关代码，使用代码摘要（函数签名、类定义）代替完整实现</li></ul></li><li><p><strong>金融领域</strong>：</p><ul><li><strong>信息特性</strong>：市场数据、财务报表、交易规则、风险指标等，时效性强</li><li><strong>优先级</strong>：最新市场数据、监管规则、风险阈值必须实时准确</li><li><strong>推理模式</strong>：基于数据分析、趋势预测、风险评估</li><li><strong>定制策略</strong>：时序数据按时间窗口聚合，历史数据存储统计特征而非原始值，规则和阈值参数化存储，通过参数引用而非重复描述</li></ul></li></ol><p><strong>定制化技术方法</strong>：</p><ol><li><p><strong>领域本体与知识图谱</strong>：</p><ul><li>构建领域特定的本体模型，定义核心概念、关系和约束</li><li>将领域知识组织为知识图谱，支持基于关系的上下文扩展和推理</li><li>上下文中只保留概念节点 ID 和关系，详细信息通过图查询按需获取</li></ul></li><li><p><strong>领域 DSL 与模板</strong>：</p><ul><li>设计领域特定语言（DSL）简洁表达领域概念，减少自然语言的冗余</li><li>预定义领域任务模板，标准化上下文结构，提高信息密度</li><li>例如医疗领域用结构化的 SOAP 笔记（Subjective, Objective, Assessment, Plan）代替自由文本</li></ul></li><li><p><strong>领域感知的压缩与摘要</strong>：</p><ul><li>训练领域特定的摘要模型，理解领域术语和重要性</li><li>基于领域知识的智能省略，例如法律文书中省略格式化条款，保留实质内容</li><li>利用领域缩写和标准化表达，例如医疗领域的疾病编码（ICD-10）、药物通用名</li></ul></li><li><p><strong>领域优化的检索策略</strong>：</p><ul><li>设计领域特定的检索索引，例如代码领域按符号和调用关系索引，法律领域按法条编号和案由索引</li><li>结合领域规则的混合检索，例如金融领域优先检索最新数据，医疗领域优先检索相关症状的诊断指南</li><li>利用领域知识进行查询扩展，例如检索"高血压"时自动扩展到相关的"降压药"、&ldquo;心血管疾病&rdquo;</li></ul></li><li><p><strong>领域特定的上下文分层</strong>：</p><ul><li>根据领域任务流程设计上下文层次，例如代码生成分为"项目架构层"、&ldquo;模块接口层&rdquo;、&ldquo;函数实现层&rdquo;</li><li>不同层次采用不同的保留策略和压缩比例</li><li>支持按层次的上下文切换和聚焦</li></ul></li></ol><p><strong>优势</strong>：</p><ul><li><strong>高效性</strong>：充分利用领域特性，上下文密度和相关性更高</li><li><strong>准确性</strong>：符合领域逻辑的上下文组织提升推理质量</li><li><strong>专业性</strong>：使用领域术语和标准，输出更符合专业要求</li><li><strong>可解释性</strong>：基于领域知识的推理路径更易于专业人士理解和验证</li></ul><p><strong>挑战</strong>：</p><ul><li><strong>开发成本</strong>：需要领域专家参与设计和验证</li><li><strong>通用性损失</strong>：过度定制可能降低跨领域的适应能力</li><li><strong>维护成本</strong>：领域知识和规则需要持续更新</li><li><strong>冷启动问题</strong>：新领域缺乏足够的领域知识积累</li></ul><p><strong>实现技术</strong>：</p><ul><li><strong>知识图谱</strong>：Neo4j、ArangoDB 存储领域本体和知识关系</li><li><strong>领域模型</strong>：基于领域语料微调的 LLM 或专门的领域编码器</li><li><strong>规则引擎</strong>：Drools、Easy Rules 管理领域规则和约束</li><li><strong>领域数据库</strong>：针对特定领域优化的数据存储（如时序数据库 InfluxDB、医疗数据库 FHIR）</li><li><strong>模板引擎</strong>：Jinja2、Mustache 管理领域模板和 DSL</li></ul><h4 id=多模型>多模型<a hidden class=anchor aria-hidden=true href=#多模型>#</a></h4><h5 id=协同方式>协同方式<a hidden class=anchor aria-hidden=true href=#协同方式>#</a></h5><p>多智能体系统中的协同方式决定了 <code>Agent</code> 之间如何分配任务、传递信息和协调行动，主要有三种协同方式：</p><h6 id=1-自由转交free-handoff>1. 自由转交（Free Handoff）<a hidden class=anchor aria-hidden=true href=#1-自由转交free-handoff>#</a></h6><p>自由转交是一种去中心化的协同方式，<code>Agent</code> 之间可以自主决定何时、向谁转交任务，无需预定义的流程或中央协调者。每个 <code>Agent</code> 根据当前任务状态、自身能力边界和其他 <code>Agent</code> 的专长，动态选择最合适的协作对象进行任务转交。这种方式灵活性最高，适合探索性和复杂多变的任务，但可能面临协调复杂、效率不确定和难以追踪的挑战。</p><h6 id=2-工作流编排workflow-orchestration>2. 工作流编排（Workflow Orchestration）<a hidden class=anchor aria-hidden=true href=#2-工作流编排workflow-orchestration>#</a></h6><p>工作流编排是一种预定义、结构化的协同方式，通过事先设计好的工作流程图或规则，明确规定任务的执行顺序、<code>Agent</code> 的职责分工和信息流转路径。通常由一个中央编排器（<code>Orchestrator</code>）负责协调和调度各个 <code>Agent</code> 的执行，确保任务按照既定流程有序推进。这种方式可预测性强、易于管理和监控，适合标准化、重复性的业务流程，但灵活性较差，难以应对动态变化的情况。</p><h6 id=3-plan--execute-协同plan--execute-collaboration>3. Plan & Execute 协同（Plan & Execute Collaboration）<a hidden class=anchor aria-hidden=true href=#3-plan--execute-协同plan--execute-collaboration>#</a></h6><p>Plan & Execute 协同是一种结合了规划智能和执行灵活性的混合方式，先由规划 Agent 制定整体执行计划，然后由执行 Agent 按计划执行，执行过程中根据实际情况动态调整计划。规划 Agent 负责任务分解和宏观决策，执行 Agent 处理具体细节并反馈结果，形成计划-执行-反馈的闭环。这种方式在结构化和灵活性之间取得平衡，适合需要宏观规划和细节执行相结合的复杂多步骤任务，既有整体规划指导又能灵活应对变化。</p><h5 id=协同类型>协同类型<a hidden class=anchor aria-hidden=true href=#协同类型>#</a></h5><p>多智能体系统中的协同类型反映了 <code>Agent</code> 之间的目标关系和互动模式，主要有三种协同类型：</p><h6 id=1-合作cooperation>1. 合作（Cooperation）<a hidden class=anchor aria-hidden=true href=#1-合作cooperation>#</a></h6><p>合作是指多个 <code>Agent</code> 共享相同或一致的目标，通过明确的分工协作来共同完成任务。每个 <code>Agent</code> 发挥自己的专长负责特定子任务，彼此之间相互配合、信息共享，最终汇总各自的贡献形成完整解决方案。这种类型强调团队协作和优势互补，适合复杂任务的模块化分解，能够充分利用不同 <code>Agent</code> 的专业能力，但需要良好的协调机制来避免重复劳动和信息孤岛。</p><h6 id=2-竞争competition>2. 竞争（Competition）<a hidden class=anchor aria-hidden=true href=#2-竞争competition>#</a></h6><p>竞争是指多个 <code>Agent</code> 针对同一问题独立提出不同的解决方案，通过辩论、评估或博弈的方式相互挑战和质疑，最终选出最优方案或综合各方观点。这种类型利用观点冲突和多样性来发现问题、纠正偏差、提升决策质量，类似于"红队-蓝队"对抗或多角度审视。竞争机制能够有效避免单一视角的盲点和群体思维陷阱，激发创新思维，但可能增加计算成本和决策时间，需要合理的评判标准来裁定优劣。</p><h6 id=3-竞合coopetition>3. 竞合（Coopetition）<a hidden class=anchor aria-hidden=true href=#3-竞合coopetition>#</a></h6><p>竞合是合作与竞争的混合模式，<code>Agent</code> 之间在某些环节合作、在某些环节竞争，既有共同目标又存在局部利益冲突。例如多个 <code>Agent</code> 共同收集信息（合作），但各自独立提出解决方案并竞争最终采纳权（竞争），或者在迭代优化过程中交替进行协作改进和对抗验证。这种类型结合了合作的效率和竞争的质量保障，适合需要平衡多样性和一致性的复杂场景，能够在保持团队协同的同时激发个体创造力，但需要精心设计合作与竞争的边界和转换机制。</p><h5 id=通信结构>通信结构<a hidden class=anchor aria-hidden=true href=#通信结构>#</a></h5><p>多智能体系统中的通信结构定义了 <code>Agent</code> 之间信息交换的拓扑关系和消息流转模式，主要有三种通信结构：</p><h6 id=1-集中式centralized>1. 集中式（Centralized）<a hidden class=anchor aria-hidden=true href=#1-集中式centralized>#</a></h6><p>集中式通信结构采用中心节点（如协调者或编排器）作为信息枢纽，所有 <code>Agent</code> 之间的通信都通过中心节点中转和协调。中心节点负责接收各 <code>Agent</code> 的消息、进行任务分配、协调执行顺序、汇总结果，其他 <code>Agent</code> 不直接相互通信。这种结构管理简单、易于监控和全局优化，适合需要严格控制和集中决策的场景，但中心节点可能成为性能瓶颈和单点故障风险，且扩展性受限于中心节点的处理能力。</p><h6 id=2-去中心化decentralized>2. 去中心化（Decentralized）<a hidden class=anchor aria-hidden=true href=#2-去中心化decentralized>#</a></h6><p>去中心化通信结构中没有固定的中心节点，<code>Agent</code> 之间采用点对点（P2P）的方式直接通信，每个 <code>Agent</code> 可以自主决定与谁交互、何时交互。<code>Agent</code> 之间地位平等，通过自组织和自协调完成任务，信息在网络中以分布式方式传播和处理。这种结构灵活性高、容错性强、无单点故障，适合动态变化和大规模分布式场景，但协调复杂度高，可能出现信息冗余或不一致，全局优化困难，需要设计良好的共识机制和冲突解决策略。</p><h6 id=3-分层式hierarchical>3. 分层式（Hierarchical）<a hidden class=anchor aria-hidden=true href=#3-分层式hierarchical>#</a></h6><p>分层式通信结构将 <code>Agent</code> 组织为多层次的树状或金字塔结构，不同层级承担不同角色和职责。高层 <code>Agent</code> 负责宏观规划、战略决策和跨域协调，中层 <code>Agent</code> 负责任务分解和区域管理，底层 <code>Agent</code> 负责具体执行和数据采集。通信主要发生在相邻层级之间，上层向下层下达指令和目标，下层向上层反馈结果和状态。这种结构兼具集中式的可控性和去中心化的扩展性，适合大规模复杂系统和组织化任务，能够实现职责分离和抽象层次管理，但层级过多可能导致通信延迟和信息失真，需要平衡层次深度和通信效率。</p><h5 id=协同策略>协同策略<a hidden class=anchor aria-hidden=true href=#协同策略>#</a></h5><p>多智能体系统中的协同策略决定了 <code>Agent</code> 如何进行决策和行动选择，主要有三种协同策略：</p><h6 id=1-基于角色role-based>1. 基于角色（Role-Based）<a hidden class=anchor aria-hidden=true href=#1-基于角色role-based>#</a></h6><p>基于角色的协同策略为每个 <code>Agent</code> 分配明确的角色定位和职责范围，<code>Agent</code> 根据自己的角色来决定行为模式和交互方式。例如在软件开发团队中，可以设置产品经理、架构师、开发者、测试工程师等不同角色，每个角色有特定的专业知识、权限边界和工作流程。这种策略通过角色分工实现专业化和责任明确，便于管理和协调，适合职责清晰的结构化任务，但角色设计的合理性直接影响系统效能，且角色固化可能降低灵活性。</p><h6 id=2-基于规则rule-based>2. 基于规则（Rule-Based）<a hidden class=anchor aria-hidden=true href=#2-基于规则rule-based>#</a></h6><p>基于规则的协同策略通过预定义的规则集来指导 <code>Agent</code> 的协同行为，规则明确规定在特定条件下应该采取什么行动、与谁协作、如何处理冲突。规则可以是简单的 if-then 条件语句，也可以是复杂的业务逻辑和约束条件。这种策略具有确定性和可解释性，行为可预测且易于审计，适合有明确规范和合规要求的领域（如金融、医疗），但规则的完备性和维护成本是挑战，难以应对规则未覆盖的新情况，且规则冲突时需要优先级机制。</p><h6 id=3-基于模型model-based>3. 基于模型（Model-Based）<a hidden class=anchor aria-hidden=true href=#3-基于模型model-based>#</a></h6><p>基于模型的协同策略让 <code>Agent</code> 通过学习和推理来自主决定协同行为，而非依赖固定的角色或规则。<code>Agent</code> 可以使用机器学习模型（如强化学习）从历史经验中学习最优协作策略，或使用大语言模型进行情境理解和动态决策。这种策略具有高度的自适应性和智能性，能够处理复杂多变的场景，发现隐含的协作模式，适合开放性和不确定性高的任务，但模型的训练成本高、决策过程可解释性差，且需要大量数据和计算资源，模型质量直接决定协同效果。</p><h5 id=协同机制>协同机制<a hidden class=anchor aria-hidden=true href=#协同机制>#</a></h5><p>多智能体系统中的协同机制决定了 <code>Agent</code> 协作关系的建立方式和时机，主要有两种协同机制：</p><h6 id=1-静态协同static-collaboration>1. 静态协同（Static Collaboration）<a hidden class=anchor aria-hidden=true href=#1-静态协同static-collaboration>#</a></h6><p>静态协同机制在系统设计阶段就预定义好 <code>Agent</code> 之间的协作流程、交互关系和任务分配方案，运行时严格按照既定流程执行。协作图（包括 <code>Agent</code> 角色、连接关系、通信路径、执行顺序等）在启动前已经确定，不会因任务内容或执行状态而改变。这种机制具有高度的稳定性和可预测性，执行效率高且易于测试验证，适合流程固定、需求明确的标准化场景（如生产流水线、审批流程），但缺乏灵活性，难以应对任务变化和异常情况，扩展新功能需要重新设计整个协作流程。</p><h6 id=2-动态协同dynamic-collaboration>2. 动态协同（Dynamic Collaboration）<a hidden class=anchor aria-hidden=true href=#2-动态协同dynamic-collaboration>#</a></h6><p>动态协同机制根据任务的具体需求和实时执行状态，在运行时动态创建和调整 <code>Agent</code> 之间的协作图。系统会分析任务特征、评估可用 <code>Agent</code> 的能力，实时决定需要哪些 <code>Agent</code> 参与、如何分工、以什么顺序执行，协作关系可以随着任务进展而演化。这种机制具有高度的灵活性和适应性，能够根据实际情况优化资源配置，适合复杂多变、需求不确定的场景（如应急响应、个性化服务），但动态决策增加了系统复杂度和计算开销，协作图的生成质量依赖于任务理解和 <code>Agent</code> 能力评估的准确性，且运行时的不确定性增加了调试和故障排查的难度。</p><h4 id=记忆系统>记忆系统<a hidden class=anchor aria-hidden=true href=#记忆系统>#</a></h4><h5 id=memgpt>MEMGPT<a hidden class=anchor aria-hidden=true href=#memgpt>#</a></h5><p><a href=https://arxiv.org/abs/2310.08560>https://arxiv.org/abs/2310.08560</a></p><p>MemGPT（Memory-enhanced GPT）是一个突破性的记忆系统，通过模拟操作系统的虚拟内存管理机制来突破大语言模型的上下文窗口限制。它将记忆分为主内存（main context）和外部存储（external context），通过智能的分页调度算法在有限的上下文窗口中动态加载最相关的记忆片段。MemGPT 引入了类似操作系统的内存管理指令集，Agent 可以显式地调用 <code>core_memory_append</code>、<code>core_memory_replace</code>、<code>archival_memory_insert</code>、<code>archival_memory_search</code> 等函数来管理自己的记忆，实现了对长期对话历史和大规模知识库的高效管理，使 Agent 能够在无限长的对话中保持连贯性和个性化。</p><h5 id=a-mem>A-MEM<a hidden class=anchor aria-hidden=true href=#a-mem>#</a></h5><p><a href=https://arxiv.org/abs/2502.12110>https://arxiv.org/abs/2502.12110</a></p><p>A-MEM（Adaptive Memory）是一种自适应的多层次记忆系统，核心特点是根据信息的访问模式和重要性动态调整记忆的存储层级和保留策略。它采用分层存储架构（热-温-冷三层），结合访问频率、时间衰减和语义相关性等多维度指标，自动将记忆在不同存储层之间迁移。A-MEM 引入了记忆强化机制，被频繁访问或被 Agent 标记为重要的记忆会得到强化，衰减速度变慢并优先保留，而长期未使用的记忆则逐渐降级到冷存储甚至被遗忘。这种自适应机制使 Agent 能够像人类一样选择性地记住重要信息，自动平衡记忆容量和信息完整性。</p><h5 id=memory-os-of-ai-agent>Memory OS of AI Agent<a hidden class=anchor aria-hidden=true href=#memory-os-of-ai-agent>#</a></h5><p><a href=https://arxiv.org/abs/2506.06326>https://arxiv.org/abs/2506.06326</a></p><p>Memory OS 是一个为 AI Agent 设计的完整记忆操作系统，提供了统一的记忆管理抽象层和丰富的记忆操作接口。它将记忆管理从 Agent 的核心逻辑中解耦出来，提供类似操作系统的系统调用接口，包括记忆的创建、读取、更新、删除、检索、索引、压缩、归档等全生命周期管理功能。Memory OS 支持多种记忆类型（情景记忆、语义记忆、程序记忆）和存储后端（向量数据库、图数据库、关系数据库），提供统一的查询语言和事务保证，使不同的 Agent 应用能够基于标准化的记忆接口进行开发，大幅降低记忆系统的实现复杂度和提高可移植性。</p><h5 id=m3-agent>M3-Agent<a hidden class=anchor aria-hidden=true href=#m3-agent>#</a></h5><p><a href=https://arxiv.org/pdf/2508.09736>https://arxiv.org/pdf/2508.09736</a></p><p>M3-Agent（Multi-Modal Multi-Memory Agent）是一个支持多模态和多记忆类型的综合记忆系统，特别强调跨模态信息的统一记忆和关联。它能够同时处理和记忆文本、图像、音频、视频等多种模态的信息，通过多模态编码器将不同模态统一映射到共享的语义空间，实现跨模态的记忆检索和推理。M3-Agent 区分了不同类型的记忆（如事实记忆、经验记忆、技能记忆、社交记忆），为每种记忆类型设计专门的存储结构和检索策略，并通过记忆融合机制将多源多模态的记忆片段整合为连贯的知识表示，使 Agent 能够在复杂的多模态交互场景中保持丰富的记忆能力。</p><h5 id=agent-kb>Agent KB<a hidden class=anchor aria-hidden=true href=#agent-kb>#</a></h5><p><a href=https://arxiv.org/pdf/2507.06229>https://arxiv.org/pdf/2507.06229</a></p><p>Agent KB（Agent Knowledge Base）是一个面向 Agent 的知识库系统，专注于结构化知识的组织和高效检索。与传统记忆系统侧重对话历史和经验不同，Agent KB 强调领域知识的系统化管理，采用知识图谱作为核心数据结构，将实体、概念、关系、规则等知识元素组织为可推理的图结构。它提供了知识的增量更新、版本管理、一致性校验、冲突解决等企业级功能，支持基于图遍历的复杂查询和多跳推理，并能够与外部知识源（如维基百科、企业数据库）进行知识同步和融合。Agent KB 使 Agent 能够基于结构化知识进行精确推理和可解释决策，特别适合知识密集型的专业领域应用。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://genluo.github.io/my-blog/tags/ai/>AI</a></li></ul><nav class=paginav><a class=next href=https://genluo.github.io/my-blog/posts/clangformat/><span class=title>Next »</span><br><span>Clangformat</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on x" href="https://x.com/intent/tweet/?text=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94&amp;url=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f&amp;hashtags=AI"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f&amp;title=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94&amp;summary=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94&amp;source=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f&title=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on whatsapp" href="https://api.whatsapp.com/send?text=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94%20-%20https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on telegram" href="https://telegram.me/share/url?text=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94&amp;url=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Agent 技术调研 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Agent%20%e6%8a%80%e6%9c%af%e8%b0%83%e7%a0%94&u=https%3a%2f%2fgenluo.github.io%2fmy-blog%2fposts%2fagent%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://genluo.github.io/my-blog/>Genluo</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>